% Chapter06 Discounted Markov Decision Problems, Markov Decision Processes Discrete Stochastic Dynamic Programming.

\section{Discounted Markov Decision Problems}%
\label{sec:discounted_markov_decision_problems}

Assumptions in this chapter:
\begin{enumerate}
    \item Stationary rewards and transition probabilities; $ r(s, a) $ and $ p(s' | s, a) $ do not vary from decision epoch to decision epoch.
    \item Bounded rewards; $ \left| r(s, a) \right| \le M < \infty $.
    \item Discount factor $ \lambda $.
    \item Discrete state spaces.
\end{enumerate}

\subsection{POLECY EVALUATION (Stationary Policy)}%
\label{sub:polecy_evaluation}

\[
    v^*_\lambda(s) = \sup_{\pi \in \Pi^{HR}} v^\pi_\lambda(s) = \sup_{\pi \in \Pi^{MR}} v^\pi_\lambda(s)
\]
Let $ \pi = (d_1, d_2, \ldots) \in \Pi^{MR} $,then 
\[
    v^\pi_\lambda(s_1) = \mathbb{E}^\pi_{s_1} \left\{ \sum^{\infty}_{t=1} \lambda^{t-1} r(X_t, Y_t) \right\}
    = r_{d_1} + \lambda P_{d_1} v^{\pi' = \left\{ d_2, d_3, \ldots \right\}}_\lambda
\]
Let $ d^\infty = (d, d, \ldots) $, then $ v^{d^\infty}_\lambda(s_1) = r_d(s_1) + \lambda P_d v^{d^\infty}_\lambda $. \\
Let $ \forall v \in V, L_d v = r_d + \lambda P_d v $, then $ v^{d^\infty}_\lambda = L_d v^{d^\infty}_\lambda $, which means $ v^{d^\infty}_\lambda $ is a fixed point of $ L_d $ in V.

\begin{theorem}
Suppose $ 0 \le \lambda < 1 $. Then $ \forall d^\infty $ with $ d \in D^{MR} $, $ \vec v^{d^\infty}_\lambda $ is the unique solution in V of $ \vec v = r_d + \lambda P_d \vec v $, and $ \vec v^{d^\infty}_\lambda = {(I - \lambda P_d)}^{-1} r_d $.
    \begin{proof}
        Key theorem:
    $ \Arrowvert P_d \Arrowvert = 1 $ and $ \sigma (\lambda P_d) \le \Arrowvert \lambda P_d \Arrowvert = \lambda \le 1$, then $ {(I - \lambda P_d)}^{-1} $ exists.
        \[
            \vec v = {(I - \lambda P_d)}^{-1} r_d = \sum^{\infty}_{t=1} \lambda^{t-1} P^{t-1}_d r_d = \vec v^{d^\infty}_\lambda
        \]
    \end{proof}
\end{theorem}

\begin{lemma}
    \begin{enumerate}
        \item $ \vec u \succeq \vec 0 \Rightarrow {(I - \lambda P_d)}^{-1} \vec u \succeq \vec u \succeq \vec 0 $
        \item $ \vec u \succeq \vec v \Rightarrow {(I - \lambda P_d)}^{-1} \vec u \succeq {(I - \lambda P_d)}^{-1} \vec v $
        \item $ \vec u \succeq \vec 0 \Rightarrow \vec u^T {(I - \lambda P_d)}^{-1} \succeq \vec u^T $
    \end{enumerate}
\end{lemma}

\subsection{OPTIMALITY EQUATIONS}%
\label{sub:optimality_equations}

Optimality equations or Bellamn equations (in discounted MDP):
\[
    v(s) = \sup_{a \in A_s} \left\{ r(s, a) + \sum^{}_{s' \in S} \lambda p(s' | s, a) v(s') \right\}
\]

\begin{lemma}
    $ \forall v \in V, 0 \le \lambda < 1, \sup_{d \in D^{MD}} \left\{ r_d + \lambda P_d v \right\} = \sup_{d \in D^{MR}} \left\{ r_d + \lambda P_d v \right\}$ 
    \begin{proof}
        First, $ D^{MD} \subset D^{MR} $, so $ \sup_{d \in D^{MD}} \left\{ r_d + \lambda P_d v \right\}\preceq \sup_{d \in D^{MR}} \left\{ r_d + \lambda P_d v \right\} $.
    Second, $ \forall d^{MR} \in D^{MR} $,
    \[
        \sum^{}_{a \in A_s} q_{d^{MR}}(a) \left[ r(s, a) + \sum^{}_{s' \in S} \lambda p(s' | s, a) v(s') \right]
        \le \sup_{a \in A_s} \left\{ r(s, a) + \sum^{}_{s' \in S} \lambda p(s'|s, a) v(s') \right\}
    \]
    which means,
    \[
        r_{d^{MR}} +  \lambda P_{d^{MR}} v \preceq \sup_{d \in D^{MD}} \left\{ r_d + \lambda P_d v \right\}
        \Rightarrow \sup_{d \in D^{MR}}\left\{ r_d + \lambda P_d v \right\}
        \preceq \sup_{d \in D^{MD}}\left\{ r_d + \lambda P_d v \right\}
    \]
    
    \end{proof}
\end{lemma}

\begin{definition}
    (Bellman operator).
    \begin{equation}
        \forall v \in V, \mathcal{L} v = \sup_{d \in D^{MD}} \left\{ r_d + \lambda P_d v \right\}
    \end{equation}
    If the supremum is attained for all $ v \in V $, we define $ L $ by
    \begin{equation}
        \forall v \in V, Lv = \max_{d \in D^{MD}}\{r_d + \lambda P_d v\}
    \end{equation}
\end{definition}

\begin{theorem}
    Suppose there exists a $ v \in V $ for which
    \begin{enumerate}
        \item $ v \succeq \mathcal{L} v \Rightarrow v \succeq v^*_\lambda $;
        \item $ v \preceq \mathcal{L} v \Rightarrow v \preceq v^*_\lambda$;
        \item $ v = \mathcal{L} v \Rightarrow v $ is unique and $ v = v^*_\lambda $.
    \end{enumerate}
    \begin{proof}
        First, we proof 1.\\
        $ \forall \pi = (d_1, d_2, \ldots) \in \Pi^{MR} $,
        \begin{align*}
            v \succeq& \sup_{d \in D^{MD}} \left\{ r_d + \lambda P_d v \right\} = \sup_{d \in D^{MR}} \left\{ r_d + \lambda P_d v \right\} \\
            \succeq& r_{d_1} + \lambda P_{d_1} v = \sum^{n}_{t=1} {(\lambda P^\pi)}^{k-1} r_{d_t} + {(\lambda P^\pi)}^n v\\
            v - v^\pi_\lambda \succeq& {(\lambda P^\pi)}^n v - \sum^{\infty}_{t = n+1} {(\lambda P^\pi)}^{t-1} r_{d_t} \\
            \succeq& - \lambda^n \Arrowvert v \Arrowvert_{\infty} \cdot \vec e
            - \lambda^n \cdot \frac{M}{1-\lambda} \cdot \vec e
        \end{align*}
        Because $ r $ is bounded, so $ \forall \epsilon, \exists N $, when $ n \ge N $, we have
        \[
            v \succeq v^\pi_\lambda - \epsilon \cdot \vec e
        \]
        \[
            v \succeq \sup_{\pi \in \Pi^{MR}} v^\pi_\lambda = \sup_{\pi \in \Pi^{HR}} v^\pi_\lambda = v^*_\lambda
        \]
        Second, we proof 2.\\
        If $ v \preceq \mathcal{L} v $, by definition of $ \sup $, we have
        \[
            \forall \epsilon, \exists d \in D^{MD}, v \preceq r_d + \lambda P_d v + \epsilon \cdot \vec e 
        \]
        \[
            \Rightarrow v \preceq {(I - \lambda P_d)}^{-1}(r_d + \epsilon \cdot \vec e)
        = v^{\pi_d}_{\lambda} + {(1 - \lambda)}^{-1} \epsilon \cdot \vec e
    \preceq \sup_{\pi \in \Pi^{HR}} v^\pi_{\lambda} + {(1-\lambda)}^{-1} \epsilon \cdot \vec e
        \]
    \end{proof}
\end{theorem}

The following norm is supremum norm.
\begin{theorem}
    \textbf{(Banach Fixed-Point Theorem).} Suppose U is a Banach space and $ T: U \rightarrow U $ is a contraction mappintwith contraction parameter $ \lambda $.Then
    \begin{enumerate}
        \item there exists a unique $ v^* $ in U such that $ T v^* = v^* $;
            \item $ \forall v^0 \in U, \lim_{n \to \infty} v^n = \lim_{n \to \infty} T^n v^0 = v^* $.
    \end{enumerate}
    \begin{proof}
        \begin{align*}
            \forall m \ge 1,\quad \Arrowvert v^{n+m} - v^n \Arrowvert 
            \le& \sum^{m-1}_{k=0} \Arrowvert v^{n+k+1} - v^{n+k} \Arrowvert
            = \sum^{m-1}_{k=0} \Arrowvert T^{n+k} v^1 - T^{n+k} v^{0} \Arrowvert\\
            \le& \sum^{m-1}_{k=0} \lambda^{n+k} \Arrowvert v^1 - v^{0} \Arrowvert
            = \frac{\lambda^n (1-\lambda^m) }{(1-\lambda)} \Arrowvert v^1 - v^0 \Arrowvert
        \end{align*}
        It follows that $ \left\{ v^n \right\} $ is a Cauchy sequence.
        From the completeness of $ U $, it follows that $ \left\{ v^n \right\} $ has a limit $ v^\infty \in U $.
        \begin{align*}
            0 \le& \Arrowvert T v^\infty - v^\infty \Arrowvert 
            \le \Arrowvert T v^\infty - v^n \Arrowvert + \Arrowvert v^n - v^\infty \Arrowvert \\
            =& \Arrowvert Tv^\infty - Tv^{n-1} \Arrowvert + \Arrowvert v^n - v^\infty \Arrowvert
            \le \lambda \Arrowvert v^\infty - v^{n-1} \Arrowvert + \Arrowvert v^n - v^\infty \Arrowvert
            \rightarrow 0
        \end{align*}
        which means that $ v^\infty$ is a fixed point of T.
        Let $ u^* $ and $ v^* $ are fixed points of T, then
        \[
            \Arrowvert u^* - v^* \Arrowvert = \Arrowvert Tu^* - Tv^* \Arrowvert
            \le \lambda \Arrowvert u^* - v^* \Arrowvert
            \Rightarrow u^* = v^*
        \]
    \end{proof}
\end{theorem}

\begin{lemma}
    Suppose that $ 0 \le \lambda < 1 $; then $ L $ and $ \mathcal{L} $ are contraction mappings on V.
    \begin{proof}
        Let $ u, v \in V $,corresponding optimal actions are $ a_u, a_v $, fix $ s \in S $, without loss of generality, let $ Lu(s) \ge Lv(s) $.
        \begin{align*}
            0 \le& Lu(s) - Lv(s) = r(s, a_u) + \sum^{}_{s' \in S} \lambda p(s'|s, a_u) u(s') - Lv(s)\\
            \le& \sum^{}_{s' \in S} \lambda p(s'|s, a_u) (u(s') - v(s')) \le \lambda \Arrowvert u - v \Arrowvert_\infty\\
        \end{align*}
        $ \forall s \in S $, we have $ \left| Lu(s) - Lv(s) \right| \le \lambda \Arrowvert u - v \Arrowvert_\infty $ \\
        The proof of $ \mathcal{L} $ is analogue.
    \end{proof}
\end{lemma}

\begin{theorem}
    Suppose $ 0 \le \lambda < 1 $, $ S $ is finite or countable, and $ r(s,a) $ is bounded.
    If $ V $ is a complete normed linear space, there exists a unique $ v^* \in V $ satisfying $ Lv^*  = v^* $,
    and $ v^* = v^*_\lambda $.
\end{theorem}

\begin{definition}
    For $ v \in V $, call a decision rule $ d_v \in D^{MD} $ v-improving if
    \[
        d_v \in \arg\max_{d \in D^{MD}} \left\{ r_d + \lambda P_d v \right\} \Leftrightarrow L_{d_v} v = Lv
    \]
    Clarify:
    \begin{enumerate}
        \item $ v^{d^\infty_v}_\lambda $ needs not be greater than or equal to $ v $.
        \item Even if $ r_{d_v} + \lambda P_{d_v} v \succeq v $, $ v^{d^\infty_v}_\lambda $ exceeds  v in some component only if $ r_{d_v} (s') + \lambda P_{d_v} v(s') > v(s') $.
        \item $ d^* $, $ v^*_\lambda $-improving, is called conserving decision rule.
    \end{enumerate}
\end{definition}

\begin{theorem}
    If supremum is attained, then $ \exists d \in D^{MD}, d^\infty \in \Pi^{MD}$, satisfies $v^{d^\infty}_\lambda = v^*_\lambda $.
    So we can calculate that $ v^*_\lambda = \sup_{d \in D^{MD}} v^{d^\infty}_\lambda $.
    \begin{proof}
        \[
            v^*_\lambda = L v^*_\lambda = L_{d_{v^*_\lambda}}v^*_\lambda
            \Rightarrow v^*_\lambda = v^{d^\infty_{v^*_\lambda}}_\lambda
        \]
    \end{proof}
\end{theorem}

\begin{theorem}
    Assume S is discrete, and either
    \begin{enumerate}
        \item $ A_s $ is finite for each $ s \in S $, or
        \item $ A_s $ is compact, $ r(s,a) $ is continuous in a for each $ s \in S $, and for each $ s' \in S $ and $ s \in S $, $ p(s' | s, a) $ is continuous in a, or
        \item $ A_s $ is compact, $ r(s, a) $ is upper semicontinuous in $ a $ for each $ s \in S $, and for each $ s' \in S $ and $ s \in S $, $ p(s' | s, a) $ is lower semicontinuous in a.
    \end{enumerate}
    Then there exists an optimal deterministic stationary policy.
\end{theorem}

If the supremum is not attained in $ \mathcal{L}v $, then optimal policies need not exist.
\begin{theorem}
    Support S is finite or countable, then for all $ \epsilon > 0 $ there exists an $ \epsilon-optimal $deterministic stationary policy.
    \begin{proof}
        Take $ d_{\epsilon} $ satisfying
        \[
            r_{d_{\epsilon}} + \lambda P_{d_{\epsilon}} v^*_{\lambda} \succeq \sup _{d \in D^{MD}} \left\{ r_d + \lambda P_d v^*_{\lambda} \right\} - (1-\lambda)\epsilon \vec{1} = v^*_{\lambda} - (1-\lambda) \epsilon \vec{1}
        \]
        \[
            v^{d^{\infty}_{\epsilon}}_{\lambda} = {(I - \lambda P_{d_{\epsilon}})}^{-1}r_{d_{\epsilon}} \succeq v^*_{\lambda} - (1-\lambda)\epsilon{(I - \lambda P_{d_{\epsilon}})}^{-1} \vec{1} = v^*_{\lambda} - \epsilon \vec{1}
        \]
    \end{proof}
\end{theorem}

\subsection{VALUE ITERATION AND ITS VARIANTS}%
\label{sub:value_iteration_and_its_variants}

\subsubsection{Rates of Convergence}%

Rate of Convergence
\begin{enumerate}
    \item linear convergence or quadratic convergence: $ \Arrowvert y_{n+1} - y^* \Arrowvert \le K \Arrowvert y_n - y^* \Arrowvert^\alpha$;
    \item superlinearly convergence: $ \limsup_{n \rightarrow \infty} \frac{ \Arrowvert y_{n+1} - y^* \Arrowvert}{ \Arrowvert y_n - y^* \Arrowvert} = 0 $;
    \item asymptotic average rate of convergence $ \limsup_{n \rightarrow \infty} {\left[ \frac{\Arrowvert y_n - y^* \Arrowvert}{\Arrowvert y_0 - y^* \Arrowvert}  \right]}^{1/n} $
\end{enumerate}

\subsubsection{Value Iteration}%

\begin{algorithm}[h!]
    \caption{Value Iteration Algorithm}
    \begin{algorithmic}
        \Require{$ \epsilon > 0 $}
        \Ensure{$ v^0 \in V $}
        \For{$ n = 1, 2, \ldots $}
            \State{$\forall s \in S, v^{n+1}(s) = \max_{a \in A_s} \left\{ r(s,a) + \sum^{}_{s' \in S} \lambda p(s'|s, a) v^n(s') \right\} $}
            \If{$ \Arrowvert v^{n+1} - v^n \Arrowvert < \epsilon (1-\lambda) / (2\lambda)$}
                \State{break.}
            \EndIf.
        \EndFor.
        \State\Return{$ d_{\epsilon}(s) \in \arg\max_{a \in A_s} \left\{ r(s,a) + \sum^{}_{s' \in S} \lambda p(s' | s, a) v^{n+1}(s') \right\} $}
    \end{algorithmic}
\end{algorithm}

\begin{theorem}
    $ {(d_{\epsilon})}^{\infty} $ is $ \epsilon-optimal $.
    \begin{proof}
        \[ \Arrowvert v^{n+1} - v^n \Arrowvert = \Arrowvert Lv^n - Lv^{n-1} \Arrowvert \le \lambda^{n-1} \Arrowvert v^1 - v^0 \Arrowvert \]\\
        so 
        \[ \exists N, \forall n > N \ge 1 + \log\left( \frac{\epsilon(1-\lambda)}{\lambda^2 \Arrowvert v^1 - v^0 \Arrowvert}  \right), \Arrowvert v^{n+1} - v^n \Arrowvert < \epsilon(1-\lambda)/(2\lambda). \]\\
        \begin{align*}
            \Arrowvert v^{d^{\infty}_\epsilon} - v^{n+1} \Arrowvert
            =& \Arrowvert L_{d_{\epsilon}} v^{d_{\epsilon}^{\infty}} - v^{n+1} \Arrowvert\\
            \le& \Arrowvert L_{d_{\epsilon}} v^{d_{\epsilon}^{\infty}} - L_{d_{\epsilon}} v^{n+1} \Arrowvert
            + \Arrowvert L v^{n+1}- L v^{n} \Arrowvert\\
            \le& \lambda\Arrowvert v^{d_{\epsilon}^{\infty}} - v^{n+1} \Arrowvert
            + \lambda\Arrowvert v^{n+1}- v^{n} \Arrowvert\\
            \Arrowvert v^{d^{\infty}_\epsilon} - v^{n+1} \Arrowvert
            \le& \frac{\lambda}{1-\lambda} \Arrowvert v^{n+1} - v^{n} \Arrowvert.\\
            Analogously,& \Arrowvert v^{n+1}- v^* \Arrowvert \le \frac{\lambda}{1-\lambda} \Arrowvert v^{n+1}-v^{n} \Arrowvert.\\
            \Arrowvert v^{d^{\infty}_\epsilon} - v^{*} \Arrowvert
            \le& \Arrowvert v^{d^{\infty}_\epsilon} - v^{n+1} \Arrowvert +
            \Arrowvert v^{n+1} - v^{*} \Arrowvert \le \epsilon
        \end{align*}
    \end{proof}
\end{theorem}

\begin{theorem}
    \textbf{(monotone).}
    If $ u \succeq v$, then $ Lu \succeq Lv $.
    \begin{proof}
        \begin{align*}
            Lu - Lv =& \max_{d \in D^{MD}} (r_d + \lambda P_{d} u) - \max_{d \in D^{MD}} (r_d + \lambda P_{d} v)\\
            =& \max_{d \in D^{MD}} (r_d + \lambda P_{d} u) - (r_{d_{v}} + \lambda P_{d_{v}} v)\\
            \succeq& (r_{d_{v}}+ \lambda P_{d_{v}} u) - (r_{d_{v}} + \lambda P_{d_{v}} v)\\
            =& \lambda P _{d_{v}} (u - v) \succeq \vec{0}
        \end{align*}
    \end{proof}
\end{theorem}

Therefore, if $ Lv^0 \succeq(\preceq) v^0 $, then value iteration converges monotonically to $ v^* $.

\begin{theorem}
    \textbf{(Convergence of value iteration).}
    \begin{enumerate}
        \item $ \Arrowvert v^{n+1} - v^*_\lambda \Arrowvert = \Arrowvert Lv^n - Lv^*_\lambda \Arrowvert \le \lambda \Arrowvert v^n - v^*_\lambda \Arrowvert $
    \item $ \frac{\Arrowvert v^{n} - v^*_\lambda \Arrowvert}{\Arrowvert v^0 - v^*_\lambda \Arrowvert} \le \lambda^{n} \Rightarrow \limsup_{n \rightarrow\infty} {\left[ \frac{\Arrowvert v^{n} - v^*_\lambda \Arrowvert}{\Arrowvert v^0 - v^*_\lambda \Arrowvert}\right]}^{1/n} \le \lambda$ 
        \item $ \Arrowvert v^n - v^*_{\lambda} \Arrowvert \le \frac{\lambda^n}{1-\lambda} \Arrowvert \lambda^1 - \lambda^0 \Arrowvert$
    \end{enumerate}
    If we want change inequality into equality, we need $ v^0 \succeq(\preceq) v^* $ and $ v^1 - v^* = \lambda(v^0 - v^*) $
\end{theorem}

\subsection{POLICY ITERATION}%
\label{sub:policy_iteration}

\begin{algorithm}[h!]
    \caption{Policy Iteration Algorithm}
    \begin{algorithmic}
        \State{Select an arbitrary rule $ d_0 \in D^{MD} $}.
        \For{$ n = 1, 2, \ldots $}
            \State{Policy evaluation: $ v^n = {(I - \lambda P_{d_{n}})}^{-1} r_{d_{n}} $}
            \State{Policy improvement: $ d_{n+1} \in \arg\max_{d \in D^{MD}} \left\{ r_d + \lambda P_d v^n \right\} $}
            \If{$ d_{n+1} = d_{n} $}
                \State{break.}
            \EndIf.
        \EndFor.
        \State{\Return{$ d_{n+1} $}}
    \end{algorithmic}
\end{algorithm}

\begin{proposition}
    In policy iteration algorithm $ v^{n+1} \ge v^{n} $.
    \begin{proof}
        \[
           r_{d_{n+1}} + \lambda P _{d_{n+1}}v^n \ge r_{d_n} + \lambda P_{d_{n}} v^n = v^n   
        \]
        \[
            v^{n+1} = {(I - \lambda P_{d_{n+1}})}^{-1} r_{d_{n+1}} \ge v^{n}
        \]
    \end{proof}
\end{proposition}

If states and actions are finite, the algorithm can terminate in finite number of iterations.

\begin{definition}
    Operator $ B: V \rightarrow V $,
    \[
        Bv = \max_{d\in D^{MD}} \left\{ r_d + (\lambda P_d - I)v \right\} = Lv - v.
    \]
\end{definition}

\begin{proposition}
    $ \forall u,v \in V $ and $ d_v \in D_v $.
    \[
        Bu \ge Bv + (\lambda P_{d_{v}} - I)(u-v) \Rightarrow
        (\lambda P_{d_{v}} - I) \in \partial_{v} (Bv)
    \]
    \begin{proof}
        \begin{align*}
            Bu -Bv =& \max_{d\in D^{MD}} \left\{ r_d + (\lambda P_d - I)u \right\} - \max_{d\in D^{MD}} \left\{ r_d + (\lambda P_d - I)v \right\}\\
            \succeq& \left\{ r_{d_v} + (\lambda P_{d_v} - I)u \right\} - \left\{ r_{d_v} + (\lambda P_{d_v} - I)v \right\}\\
            \succeq& (\lambda P_{d_{v}} - I)(u - v) 
        \end{align*}
    \end{proof}
\end{proposition}

\begin{proposition}
    Suppose the sequence $ \left\{ v^n \right\} $ is obtained from the policy iteration algorithm.
    Then, for any $ d_{v^{n}} \in D _{v^{n}} $.
    \[
        v^{n+1} = v^n - {(\lambda P _{d_{v^{n}}} - I) }^{-1} B v^{n}
    \]
    \begin{proof}
        \begin{align*}
            v^{n+1} =& {(I - \lambda P_{d_{v^n}})}^{-1} r_{d_{v^{n}}} - v^n + v^n\\
            =& v^n - {(\lambda P_{d_{v^n}} - I)}^{-1} \left[ r_{d_{v^{n}}} +  {(\lambda P_{d_{v^n}} - I)}v^n \right]\\
            =& v^n - {(\lambda P _{d_{v^{n}}} - I) }^{-1} B v^{n}
        \end{align*}
    \end{proof}
\end{proposition}

\begin{definition}
    $ V_B = \left\{ v \in V; Bv \ge 0 \right\} $ ($ v \in V_B \Rightarrow v \preceq v^*$).
\end{definition}
\begin{definition}
    $ Zv = v - {(\lambda P _{d_{v}} - I) }^{-1} B v $.
\end{definition}
\begin{lemma}
    Let $ v \in V_B, d_v \in D_v, v \succeq u $. Then $ Zv \succeq L u, Zv \in V_B, Zv \succeq v$.
    \begin{proof}
        \[
           Zv = v - {(\lambda P _{d_{v}} - I) }^{-1} B v \succeq v + Bv = Lv \succeq L u   
        \]
        \[
            B(Zv) \succeq Bv + (\lambda P_{d_{v}} - I) (Zv - v) = \vec{0}
        \]
        \[
            Zv = v + {(I - \lambda P _{d_{v}}) }^{-1} B v \succeq v 
        \]
    \end{proof}
\end{lemma}
\begin{theorem}
    \textbf{(Policy iteration converges monotonically).}
    \begin{proof}
        Let $ u^k = L^k v^0 $ and $ v^k = Z^k v_0 $. We inductively show that $ v^k \in V_B $ and $ u^k \le v^k \le v^*_\lambda $.\\
        First, if $k = 0$, then $ u^0 = v^0 $ and
        \[
            Bv^0 \succeq r_{d_{0}} + (\lambda P_{d_0} - I) v^0 = \vec{0},
        \]
        therefore, $ v^0 \in V_B $ and $ v^0 \preceq v^*_{\lambda} $. Above all, $ k = 0, u^0 \preceq v^0 \preceq v^*_{\lambda} $.\\
        Then, we assume $ k \le n $, $ u^k \preceq v^k \preceq v^*_{\lambda} $ and $ B v^k \succeq \vec{0} $.
        \[
            v^{n+1} = Z v^n \in V_B \Rightarrow v^{n+1} \preceq v^*_{\lambda}.
        \]
        \[
            v^k \succeq u^k, v^{n+1} = Z v^n \succeq L u^n = u^{n+1}
        \]
    \end{proof}
\end{theorem}

\begin{theorem}
    \textbf{(Convergence Rate).}
    If policy iteration's sequence $ \left\{ v^n \right\} $ satisfies
    $ \Arrowvert P_{d_{v^n}} - P_{d_{v^*_{\lambda}}} \Arrowvert \le K \Arrowvert v^n - v^*_\lambda \Arrowvert $ (for some K),then
    \[
        \Arrowvert v^{n+1} - v^*_{\lambda} \Arrowvert \le \frac{K\lambda}{1-\lambda} \Arrowvert v^n - v^*_\lambda \Arrowvert^2
    \]
    \begin{proof}
        Let $ U_n = \lambda P_{d_{v^{n}}-I} $ and $ U_* = \lambda P_{d_{v^*_\lambda}} - I $.then
        \[
            Bv^n \succeq B v^*_\lambda + U_* (v^n - v^*_\lambda) = U_* (v^n - v^*_\lambda)
            \Rightarrow
            U^{-1}_{n} B v^n \preceq U^{-1}_n U_* (v^n - v^*_\lambda)
        \]
        \[
            0 \preceq v^*_\lambda - v^{n+1} = v^*_\lambda - v^n + U^{-1}_{n}B v^n
            \preceq U^{-1}_n (U_n - U_*)(v^*_\lambda - v^n)
        \]
        \[
            \Arrowvert v^*_{\lambda} - v^{n+1} \Arrowvert \preceq \Arrowvert U^{-1}_{n} \Arrowvert
            \Arrowvert U_n - U_* \Arrowvert \Arrowvert v^*_{\lambda} - v^n \Arrowvert \preceq \frac{\lambda}{1-\lambda} \Arrowvert P_{d_{v^n}} - P_{d_{v^*_{\lambda}}} \Arrowvert \Arrowvert v^*_\lambda - v^n \Arrowvert
        \]
    \end{proof}
\end{theorem}

Consider that $ \Arrowvert P_{d_{v^n}} - P_{d_{v^*_{\lambda}}} \Arrowvert \le K \Arrowvert v^n - v^*_\lambda \Arrowvert $ is unsatisfying, for the unkown $ v^*_\lambda $, we can change into a general condition:
\[
    \forall u, v \in V, \Arrowvert P_{d_{v}} - P_{d_{u}} \Arrowvert\le K \Arrowvert v - u \Arrowvert 
\]
\[
    \forall u, v \in V, \Arrowvert P_{d_{v}} - P_{d_{v^*_\lambda}} \Arrowvert\le K \Arrowvert v - v^*_\lambda \Arrowvert 
\]

\subsection{MODIFIED POLICY ITERATION}%
\label{sub:modified_policy_iteration}

\begin{algorithm}[h!]
    \caption{Modified Policy Iteration Algorithm (MPI)}
    \begin{algorithmic}
        \Require{$ \epsilon > 0, \left\{ m_0, m_2, \ldots \right\} $}.
        \Ensure{$ v^0 \in V_B $}.
        \For{$ n = 0, 1, \ldots $}
            \State{$ d_{n+1} \in \arg\max_{d \in D} \left\{ r_d + \lambda P_d v^n \right\} $}
            \State{$ u^0_n = r_{d_{n+1}} + \lambda P_{d_{n+1}} v^n $}
            \If{$ \Arrowvert u^0_n - v^n \Arrowvert < \epsilon(1-\lambda)/(2\lambda) $} {break} \EndIf.
            \For{$ k = 0, 1, \ldots, m_n $}
                \State{$ u^{k+1}_n = r_{d_{n+1}}+ \lambda P_{d_{n+1}} u^k_n = L_{d_{n+1}} u^k_n $}
            \EndFor.
            \State{($ v^{n+1} = L_{d_{n+1}}^{ m_n + 1 } v^n $) }
        \EndFor.
        \State{\Return{$ d_{n+1} $}}
    \end{algorithmic}
\end{algorithm}

In policy iteration, we have
\[
    v^{n+1} = v^n - {(\lambda P _{d_{v^{n}}} - I) }^{-1} B v^{n} = v^n + \sum^{\infty}_{k = 0} {\left( \lambda P_{d_{n+1}}^k B v^n \right)}
\]
\begin{proposition}
    Modified policy iteration algorithm equals:
    \[
        v^{n+1} = v^n - {(\lambda P _{d_{v^{n}}} - I) }^{-1} B v^{n} = v^n + \sum^{m_n}_{k = 0} {\left( \lambda P_{d_{n+1}}^k\right) B v^n }
    \]
    \begin{proof}
        \begin{align*}
            v^{n+1} =& v^n + \sum^{m_n}_{k=0} {\left( \lambda P_{d_{n+1}} \right)}^k \left[ r_{d_{n+1}} + \lambda P_{d_{n+1}} v^n - v^n \right]\\
            =& r_{d_{n+1}} + \lambda P_{d_{n+1}}r_{d_{n+1}} + \cdots + {\left(\lambda P_{d_{n+1}}\right)}^{m_n}r_{d_{n+1}} + {\left( \lambda P_{d_{n+1}} \right)}^{m_n + 1} v^n\\
            =& {(L_{d_{n+1}})}^{m_n+1}v^n
        \end{align*}
    \end{proof}
\end{proposition}
The preceeding proposition shows that order 0 modified policy iteration eqauals to value iteration, and order $ \infty $ modified policy iteration equals to policy iteration. 

The graph of algorithm: $ Bv $ lines and $ 45-degree $ lines.

Denote the operator $ U^m: V \rightarrow V $, 
\[
    U^m v = \max_{d \in D} \sum^{m}_{k=0} {(\lambda P_d)}^k r_d + {(\lambda P_d)}^{m+1}v.
\]
Proposition:
\begin{enumerate}
    \item $ \Arrowvert U^m u - U^m v \Arrowvert \le \lambda^{m+1} \Arrowvert u - v \Arrowvert $;
    \item The sequence $ w^{n+1} = U^m w^n $ converges in norm to $ v^*_\lambda $;
        \begin{proof}
            Assume $ w^* $ is the fixed point of $ U^m $, and let $ d^* \in D^{MD} $ be the $ v^*_\lambda-improving $ decision rule.
            \[
                v^*_\lambda = L^m v^*_\lambda = \sum^{m}_{k=0} {(\lambda P_{d^*})}^k r_{d^*} + {(\lambda P_{d^*})}^{m+1} v^*_\lambda \preceq U^m v^*_\lambda \preceq {(U^m)}^n v^*_\lambda \rightarrow w^*,
            \]
            \[
                w^* = U^m w^* \preceq L^m w^* \rightarrow v^*_\lambda
            \]
            
        \end{proof}
    \item $ v^*_{\lambda} $ is the unique fixed point of $ U^m $;
    \item $ \Arrowvert w^{n+1} - v^*_{\lambda} \Arrowvert \preceq \lambda^{m+1} \Arrowvert w^n - v^*_{\lambda} \Arrowvert $
\end{enumerate}

Denote the MPI operator $ W^m: V \rightarrow V $,
\[
    W^m v = v + \sum^{m}_{k=0} {(\lambda P_{d_{v}})}^k Bv
\]

\begin{lemma}
    For $ u \in V $ and $ v \in V $ satisfying $ u \succeq v \Rightarrow U^m u \succeq W^m v $. Furthermore, if $ u \in V_B $, then $ W^m u \succeq U^0 v = Lv $.
    \begin{proof}
        Let $ d_v \in D $ is $ v-improving $ and $ d_u \in D $ is $ u-improving $. Then
        \begin{align*}
            U^m u - W^m v \succeq& \sum^{m}_{k=0} {(\lambda P_{d_{v}})}^k r_{d_v} + {(\lambda P_{d_v})}^{m+1} u - \sum^{m}_{k=0} {(\lambda P_{d_{v}})}^k r_{d_v} - {(\lambda P_{d_v})}^{m+1} v\\
            =& {(\lambda P_{d_v})}^{m+1} (u - v) \succeq 0.
        \end{align*}
        For $ u \in V_B $,
        \begin{align*}
            W^m u = u + \sum^{m}_{k=0} {(\lambda P_{d_u})}^k Bu \succeq u + Bu = Lu \succeq r_{d_v} + \lambda P_{d_v}u \succeq Lv
        \end{align*}
    \end{proof}
\end{lemma}

\begin{lemma}
    $ u \in V_B \Rightarrow w = W^m u \in V_B $.
    \begin{proof}
        \begin{align*}
            Bw \succeq& Bu + (\lambda P_{d_u} - I)(w - u) = Bu + (\lambda P_{d_u} - I) \sum^{m}_{k=0} {(\lambda P_{d_u})}^k Bu\\
            =& {(\lambda P_{d_u})}^{m+1} Bu \succeq \vec{0}
        \end{align*}
    \end{proof}
\end{lemma}

\begin{theorem}
    \textbf{(The monotonical convergence of MPI).}
    \begin{proof}
        Define three sequence $ \left\{ v^n \right\}, \left\{ y^n \right\}, \left\{ w^n \right\} $ which corresponds to $ W^{m_n}, L $, and $ U^{m_n} $, and $ v^0 = y^0 = w^0 \in V_B $. We will show that $ v^n \in V_B, v^{n+1} \succeq v^n $, and $ w^n \succeq v^n \succeq y^n $.

        According preceeding lemma, $ v^0 \in V_B \Rightarrow v^n \in V_B $.
        
        We can get monotonous by $ v^{n+1} = v^n + \sum^{m_n}_{m=0} {(\lambda P_{d_n})}^m B v^n \succeq v^n $.

        By condunction, we assum $ w^n \succeq v^n \succeq y^n $the preceeding lemma also proofs that $ U^{m_n} w^n \succeq W^{m_n} v^{n} \succeq L y^{n} $.
    \end{proof}
\end{theorem}

Noting: $ W^{m_n + k} v^n $ can be small than $ W^{m_n} v^n $

\subsubsection{Convergence Rates}%
\label{ssub:convergence_rates}

\begin{theorem}
    Suppose $ v^0 \in V_B $ and $ \left\{ v^n \right\} $ is generated by modified policy iteration, $ d_n $ is a $ v^n-improving $ decision rule, and $ d^* $ is a $ v^*_\lambda-improving $ decision rule.
    \begin{equation}
        \Arrowvert v^{n+1} - v^*_\lambda \Arrowvert \le
        \left( \frac{\lambda (1 - \lambda^{m_n})}{1- \lambda} \Arrowvert P_{d_n} - P_{d^*} \Arrowvert + \lambda^{m_n + 1} \right) \Arrowvert v^n - v^*_{\lambda} \Arrowvert.
    \end{equation}
    \begin{proof}
        \begin{align*}
            0 \le& v^*_{\lambda} - v^{n+1} = v^*_{\lambda} - v^n - \sum^{m_n}_{k=0} {(\lambda P_{d_n})}^k B v^n \\
            \le& v^*_{\lambda} - v^n + \sum^{m_n}_{k=0} {(\lambda P_{d_n})}^k (I - \lambda P_{d^*}) (v^n - v^*_{\lambda})\\
            =& \lambda (P_{d_n} - P_{d^*}) \sum^{m_n - 1}_{k = 0} {(\lambda P_{d_n})}^k (v^n - v^*_{\lambda}) - \lambda^{m_n + 1} P^{m_n}_{d_n} P_{d^*} (v^n - v^*_{\lambda})
        \end{align*}
        Taking norms yields the result.
    \end{proof}
\end{theorem}

If $ \lim_{n \rightarrow \infty} \Arrowvert P_{d_n} - P_{d^*} \Arrowvert = 0 $, then $ \Arrowvert v^{n+1} - v^*_\lambda \Arrowvert \le \left( \lambda^{m_n + 1} + \epsilon \right) \Arrowvert v^n - v^*_\lambda \Arrowvert$.

If $ m_n \rightarrow \infty $, $ \lim\sup_{n \rightarrow \infty} \frac{ \Arrowvert v^{n+1} - v^*_{\lambda} \Arrowvert}{ \Arrowvert v^n - v^*_{\lambda} \Arrowvert} = 0 $.

\subsection{SPANS, BOUNDS, STOPPING CRITERIA, AND RELATIVE VALUE ITEARTION}%
\label{sub:spans_bounds_stopping_criteria_and_relative_value_iteartion}

\subsubsection{The Span Seminorm}%

\begin{enumerate}
    \item $ \Lambda(v) = \min_{s \in S} v(s), \Upsilon(v) = \max_{s \in S} v(s) $;
    \item $ sp(v) = \max_{s \in S} v(s) - \min_{s \in S}v(s) = \Upsilon(v) - \Lambda(v) $
        \begin{itemize}
            \item $ \forall v \in V, sp(v) \ge 0 $;
            \item $ \forall v, u \in V, sp(u+v) \le sp(u) + sp(v) $;
            \item $ \forall k \in \mathbb{R}, sp(kv) = |k| sp(v) $;
            \item $ \forall k \in \mathbb{R}, sp(v+ke) = sp(v) $;
            \item $ sp(v) = sp(-v) $;
            \item $ sp(v) \le 2 {\Arrowvert v \Arrowvert}_\infty \le 2 {\Arrowvert v \Arrowvert}_2 \le 2 \Arrowvert v \Arrowvert_1 $
        \end{itemize}
\end{enumerate}

\begin{proposition}
    Let $ v \in V, d \in D $. Then $ sp(P_d v) \le \gamma_d sp(v) $,\\
    $ \gamma_d = \max_{s, s' \in S \times S} \sum^{}_{j \in S} \max \left\{0, P_d(j |s) - P_d(j | s') \right\}$.
    \begin{proof}
        Let $ b(s, s'; j) = \min \left\{ P(j | s), P(j | s') \right\} $
        \begin{align*}
            sp(Pv) =& \max_{s, s' \in S \times S}\sum^{}_{j \in S} [P(j | s) - b(s, s';j)] v(j) - \sum^{}_{j \in S} [P(j | s') - b(s, s';j)] v(j)\\
            \le& \max_{s, s' \in S \times S}\sum^{}_{j\in S}[P(j|s) - b(s, s';j)] \Upsilon(v) - \sum^{}_{j\in S} [P(j|s') - b(s,s',j)]\Lambda(v)\\
            =& \max_{s, s' \in S \times S} \left[ 1 - \sum^{}_{j\in S} b(s, s'; j)\right] sp(v)
            = \max_{s, s' \in S \times S} \left[1 - \sum^{}_{j \in S} \min\left\{ P(j|s), P(j|s') \right\}\right] sp(v)\\
            =& \max_{s, s' \in S \times S} \left[ 1 - \sum^{}_{j\in S} (P(j|s) + P(j|s') - |P(j|s)-P(j|s')|)/2 \right] sp(v)\\
            =& \max_{s, s' \in S \times S} \left[ \frac{1}{2} \sum^{}_{j\in S} |P(j|s)-P(j|s')| \right] sp(v)\\
            =& \max_{s, s' \in S \times S} \sum^{}_{j\in S} \max\left\{ 0, P(j|s) - P(j|s') \right\} sp(v)
        \end{align*}
        $ (\left| x - y \right| = x+y - 2\min(x,y), \max(0, x-y) = x - \min(x,y), \max(0, y-x) = y - \min(x,y))$
    \end{proof}
\end{proposition}

$ \exists v' \in V $ such that $ sp(Pv) = sp(v) $:
\begin{enumerate}
    \item P's rows are equal $\Rightarrow \gamma_d = 0 \Rightarrow sp(Pv) = 0 = 0 \cdot sp(v)$;
    \item Let $ s^*, s'^* $ be $ \sum^{}_{j\in S} \max\left\{ 0, P(j|s^*) - P(j|s'^*) \right\} = \max_{s, s' \in S \times S} \sum^{}_{j\in S} \max\left\{ 0, P(j|s) - P(j|s') \right\}$, then $ v(j) = 1_{\left\{ P(j|s^*) > P(j|s'^*) \right\}} $.
        $ sp(v') = 1 $ and $ sp(Pv) \ge \sum^{}_{j \in S} P(j | s^*) v(j) - \sum^{}_{j\in S} P(j | s'^*) v(j) = \sum^{}_{j \in S} \max\left\{ 0, P(j | s^*) - P(j | s'^*) \right\} = \gamma_d sp(v)$
\end{enumerate}

$ \gamma_d $ is referred to as the Hajnal measure or delta coefficient of $ P_d $, which upper bounds the subradius (modulus of the second largest eigenvalue) of $ P_d $, $ \sigma_s(P_d) $. $ \gamma_d $ equals to 0 if all rows of $ P_d $ are equal, and equals to 1 if at least two rows of $ P_d $ are orthogonal.

\begin{theorem}
    Let \textbf{span constraction} $ T: V \rightarrow T $ and suppose there exists an $ \alpha $, $ 0 \le \alpha < 1 $ for which
    \[
        sp(Tv - Tu) \le \alpha \cdot sp(v - u)
    \]
    then
    \begin{enumerate}
        \item $ \exists v^* \in V, sp(Tv^* - v^*) = 0 $ which called \textbf{span fixed point}. Furthermore, $ Tv^* = v^* = v^* + ke $.
        \item For sequence $ \left\{ v^n \right\} $ by $ v^n = T^n v^0 $, then $ \lim_{n \rightarrow \infty} sp(v^n - v^*) = 0 $.
        \item $ sp(v^{n+1} - v^*) \le \alpha^n sp(v^0 - v^*) $
    \end{enumerate}
\end{theorem}

\subsubsection{Bounds on the Value of a Discounted Markov Decision Process}%
\label{ssub:bounds_on_the_value_of_a_discounted_markov_decision_process}

\begin{theorem}
    For $ v \in V, m \ge -1 $, and any $ v-improving $ decision rule $ d_v $,
    \begin{align*}
        G_m(v) =& v + \sum^{m}_{i=1} {(\lambda P_{d_v})}^k Bv + \lambda^{m+1}{(1-\lambda)}^{-1} \Lambda (Bv) \vec{1}, \quad \text{nondecreasing in m}\\
        G^m(v) =& v + \sum^{m}_{k=0} {(\lambda P_{d_{v^*_{\lambda}}})}^k Bv + \lambda^{m+1}{(1-\lambda)}^{-1} \Upsilon(Bv) \vec{1}, \quad \text{nonincreasing in m}\\
        G_m(v) \le& v^{{(d_v)}^\infty}_\lambda \le v^*_{\lambda} \le G^m(v)
    \end{align*}
    \begin{proof}
        We have $ 0 = B v^*_\lambda \succeq Bv + (\lambda P_{d_v} - I)(v^*_\lambda - v) $.
        Since that $ {(I - \lambda P_{d_v})}^{-1} \succeq 0 $, 
        then, $ 0 \succeq v - v^*_\lambda + {(I - \lambda P_{d_v})}^{-1} Bv $.
        \begin{align*}
            v^*_\lambda \succeq& v + \sum^{m}_{k=0} {(\lambda P_{d_v})}^k Bv + \sum^{\infty}_{k=m+1} {(\lambda P_{d_v})}^k [\Lambda(Bv)] \vec{1}\\
            =& v + \sum^{m}_{k=0} {(\lambda P_{d_v})}^k Bv + \frac{\lambda^{m+1}}{1-\lambda} [\Lambda(Bv)]\vec{1}
        \end{align*}
        Analoguely, $ Bv \succeq Bv^*_{\lambda} + (\lambda P_{d_{v^*_{\lambda}}} - I)(v - v^*_{\lambda}) \Rightarrow v^*_\lambda \preceq v + {(I - \lambda P_{d_{v^*_{\lambda}}})}^{-1} Bv \preceq v + \sum^{m}_{k=0} {(\lambda P_{d^*_\lambda})}^k Bv + \frac{\lambda^{m+1}}{1-\lambda} [\Upsilon(Bv)] \vec{1}$.
    \end{proof}
\end{theorem}

\begin{corollary}
    \begin{align*}
        v + {(1-\lambda)}^{-1} \Lambda(Bv) \vec{1}
        \preceq& v + Bv + \lambda {(1-\lambda)}^{-1} \Lambda(Bv) \vec{1} \preceq v^{d^\infty_v}_\lambda\\
        \preceq& v^*_\lambda \preceq v+Bv+ \frac{\lambda}{{1-\lambda}} \Upsilon(Bv) \vec{1}\\
        \preceq& v + {(1-\lambda)}^{-1} \Upsilon(Bv) \vec{1}
    \end{align*}
\end{corollary}

\subsubsection{Stopping Criteria}%
\label{ssub:stopping_criteria}

\begin{proposition}
    For $ v \in V $ and $ \epsilon > 0 $ that
    \[
        sp(Lv-v) = sp(Bv) < \frac{(1-\lambda)}{\lambda} \epsilon
    \]
    then,
    \[
        \Arrowvert Lv + \frac{\lambda}{1-\lambda} \Lambda(Bv) \vec{e} - v^*_\lambda \Arrowvert < \epsilon
    \]
    and 
    \[
         \Arrowvert v^{d^\infty_v}_\lambda - v^*_\lambda \Arrowvert < \epsilon
    \]
    \begin{proof} ($ w \le x \le y \le z \Rightarrow 0 \le y-x \le z-w $).
        \[
            0\preceq v^*_\lambda - v - Bv - \frac{\lambda}{1-\lambda} \Lambda(Bv) \vec{1} \preceq \frac{\lambda}{1-\lambda} sp(Bv) \vec{1}
        \]
        Because $ Lv = Bv + v $, therefore we can get the first inequation by taking norms on both side. 
        Analogously,
        \[
            0 \preceq v^*_{\lambda} - v^{d^\infty_v}_{v} \preceq \frac{\lambda}{1-\lambda} sp(Bv) \vec{1}
        \]
    \end{proof}
\end{proposition}

Here is something we need to know
\[
    \forall k, \arg\max_{d \in D} \left\{ r_d + \lambda P_d (v + k \vec{1}) \right\}
    = \arg\max_{d \in D} \left\{ r_d + \lambda P_d v + \lambda k \vec{1} \right\}
    = \arg\max_{d \in D} \left\{ r_d + \lambda P_d v \right\}
\]
\begin{theorem}
    $ \gamma = \max_{s\in S, a \in A_s, s' \in S, a' \in A_{s'}} \left[ 1- \sum^{}_{j \in S} \min \left[ p(j | s, a), p(j | s', a') \right] \right] $.
    Then $ \forall u, v \in V, sp(Lv - Lu) \le \lambda \gamma sp(v - u) $.
    \begin{proof}
        \begin{align*}
            sp(Lv - Lu) \le& \max_{s \in S}(L v(s) - L u(s)) - \min_{s \in S} (L v(s) - L u(s)) \\
            \le&\max_{s \in S}(L_{d_v} v(s) - L_{d_v} u(s)) - \min_{s \in S} (L_{d_u} v(s) - L_{d_u} u(s)) \\
            =& \max_{s \in S}(P_{d_v}(v - u) (s)) - \min_{s \in S} (\lambda P_{d_u}(v-u) (s)) \\
            \le& sp\left(\lambda \begin{bmatrix} P_{d_v} \\ P_{d_u} \end{bmatrix} (v-u)\right) \le \lambda \gamma_{d_v, d_u}(v - u) \le \lambda \gamma(v-u) \\
        \end{align*}
    \end{proof}
\end{theorem}

If $ u = Lv $ then $ \forall v \in V, sp(B^2 v) \le \lambda \gamma sp(Bv) $.
For value iteration,
\[
    \Arrowvert v^{n+2} - v^{n+1} \Arrowvert = \Arrowvert B v^{n+1} \Arrowvert = \Arrowvert B^2 v^n \Arrowvert\le \lambda \Arrowvert B v^n \Arrowvert = \lambda \Arrowvert v^{n+1} - v^n \Arrowvert
\]
\[
    sp(v^{n+2} - v^{n+1}) = sp(B^2 v^n) \le \lambda \gamma sp(B v^n) = \lambda \gamma sp(v^{n+1} - v^n)
\]

We can use $ \gamma' $ instead of $ \gamma $: $ \gamma \le 1 - \sum^{}_{j \in S} \min_{s \in S, a \in A_s} p(j | s, a) = \gamma' $.  

\begin{corollary}
    Let $ v^0 \in V $, $ \left\{ v^n \right\} $ has been generated using value iteration. Then
    \begin{enumerate}
        \item $ \lim_{n \to \infty} sp(v^n - V^*_{\lambda}) = 0 $;
        \item $ \forall n, sp(v^{n+1} - v^{*}_{\lambda}) \le {(\lambda \gamma)}^{n} sp(v^0 - v^*_{\lambda}) $;
        \item $ sp(v^{n+1} - v^n) \le {(\lambda \gamma)}^{n} sp(v^1 - v^0) $.
    \end{enumerate}
\end{corollary}

In chapter8, the following algorithm is useful.
\begin{algorithm}
    \caption{Relative Value Iteration Algorithm}
    \begin{algorithmic}
        \Require{$ \epsilon > 0 $}
        \Ensure{$ u^0 \in V$, choose $ s_0 $ set $ w^0 = u^0 - u^0(s_0) \vec{1} $}
        \For{$ n = 0, 1, \ldots $}
            \State{$ u^{n+1}  = Lw^n $}
            \State{$ w^{n+1} = u^{n+1} - u^{n+1}(s_0) \vec{1} $}
            \If{$ sp(u^{n+1} - u^{n}) < (1-\lambda)\epsilon/\lambda $} {break}\EndIf.
        \EndFor.
        \State{\Return{$ d_\epsilon \in \arg\max_{d \in D} \left\{ r_d + \lambda P_d u^n \right\} $}}
    \end{algorithmic}
\end{algorithm}

\subsection{ACTION ELIMINATION PROCEDURES}%

The advantages of using action elimination procedures:
\begin{enumerate}
    \item Reduction in size of the action sets;
    \item Get $ optimal $ policy, instead of $ \epsilon-optimal $.
\end{enumerate}

\subsubsection{Identification of Nonoptimal Actions}%

\[
    B(s,a) v = r(s, a) + \sum^{}_{s' \in S} \lambda p(s' | s, a) v(s') - v(s).
\]

\begin{proposition}
    \[
        B(s, a') v^*_{\lambda} < 0 \Rightarrow a' \notin \arg\max_{a \in A_s} \left\{ r(s,a) + \sum^{}_{s' \in S} \lambda p(s'|s,a) v^{*}_{\lambda}(s') \right\}
    \]
    \begin{proof}
        \[
            \forall s, a', B(s,a') v^*_{\lambda} \le \max_{a \in A_S} B(s,a) v^*_{\lambda} = 0;
        \]
        \[
            a' \in \arg\max_{a \in A_s} \left\{ r(s,a) + \sum^{}_{s' \in S} \lambda p(s'|s,a) v^{*}_{\lambda}(s') \right\}\Rightarrow B(s, a') v^{*}_{\lambda} = 0
        \]
    \end{proof}
\end{proposition}

Since $ v^*_{\lambda} $ is unknown, the result in preceeding proposition cannot be used in practice to identify nonoptimal actions.

\begin{proposition}
    If $ a' $ satisfies $ \exists v^L \preceq v^*_{\lambda} \preceq v^{U} $ that 
    \[
        r(s,a') + \sum^{}_{s' \in S} \lambda p(s' | s, a') v^{U}(s') < v^{L}(s)
    \]
    \begin{proof}
        \[
            B(s,a) v^{*}_\lambda \le B(s,a) v^{U} < v^{L}(s) \le v^{*}_{\lambda}(s)
        \]
    \end{proof}
\end{proposition}

\subsubsection{Action Elimination Procedures}%

\begin{definition}
    (Action Elimination Procedures)
    \begin{itemize}
        \item Policy evaluation;
        \item Action elimination;
        \item Policy Improvement over reduced action set.
    \end{itemize}
\end{definition}

Recall that
\[
    v^{n+1} = 
    \begin{cases}
        Lv^n, & \text{for value iteration} \\
        v^{n} + \sum^{m_n}_{k=0} {(\lambda P_{d_{v^n}})}^{k} B v^{n}, & \text{for modified policy iteration}\\
        {(I - \lambda P_{d_{v^n}})}^{-1} r_{d_{v^n}}, &\text{for policy iteration}
    \end{cases}
\]

We use the weakest upper: $ v^{U} = v^n + \frac{\lambda}{1 - \lambda} \Upsilon(B v^n) \vec{1} $.

Define
\[
    G_{m}(v) = v + \sum^{m-1}_{k=0} {(\lambda P_{d_v})}^{k} Bv + \lambda^{m}{(1 - \lambda)}^{-1} \Lambda(Bv) \vec{1}
\]
For value iteration $ v^L = G_0(v^{n}) $, for modified policy iteration $ v^L = G_{m_n}(v^n) $ and for policy iteration $ v^L = G_{\infty}(v^{n}) $.
Then Action $ a' $ is nonoptimal in state s at iteration n if

\[
    r(s,a') + \sum^{}_{s' \in S} \lambda p(s' | s, a') v^{n}(s') + \frac{\lambda}{1 - \lambda} \Upsilon(B v^n) < G_{m_n}(v^n) (s)
\]
Which is equal to
\[
    \frac{\lambda}{1 - \lambda} sp(B v^{n}) < L v^{n}(s) - r(s,a) - \sum^{}_{s' \in S}  \lambda p(s' | s, a) v^{n}(s')
\]
The $ \lambda/(1 - \lambda) $ can be replaced by $ \lambda\gamma_{s,a} / (1 - \lambda \gamma) $:
\[
    \gamma_{s,a} = \max_{a' \in A_S} \left\{ 1 - \sum^{}_{s' \in S} \min \left[ p(s'|s,a), p(s'|s,a') \right] \right\}
\]
\[
    \gamma = \max_{s\in S, a \in A_S, s' \in S, a' \in A_{s'}} \left\{ 1 - \sum^{}_{s' \in S} \min \left[ p(s'|s,a), p(s'|s,a') \right] \right\}
\]
\begin{proposition}
    If $ v' = v + \sum^{p}_{k=0} {(\lambda P_{d_{v}})}^k Bv $,
    \[
        \forall p, q \ge 0, G_{p}(v) \preceq G_{q}(v') \preceq v^{*}_{\lambda} \preceq G^{q}(v') \preceq G^{p}(v)
    \]
    \begin{proof}
        We proof $ G_p(v) \preceq G_0(v') = v' + \frac{1}{1-\lambda} \Lambda(Bv') \vec{1} $.
        \begin{align*}
            G_0(v') - G_p(v)=& v' + \frac{1}{1 - \lambda} \Lambda(Bv') \vec{1} - v - \sum^{p-1}_{k=0} {(\lambda P_{d_v})}^{k}Bv - \frac{\lambda^p}{1 - \lambda} \Lambda(Bv) \vec{1} \\
            =& {(\lambda P_{d_v})}^p Bv + \frac{1}{1 - \lambda} \Lambda(Bv') \vec{1} - \frac{\lambda^p}{1 - \lambda} \Lambda(Bv) \vec{1} \\
            Bv' =& Lv' - v' = L [ L^{p+1}_{d_v} v] - L^{p+1}_{d_v}v \\
            \succeq & L^{p+2}_{d_v}v - L^{p+1}_{d_v} v = L^{p+1}_{d_v} [Bv] \succeq \lambda^{p+1} \Lambda(Bv) \vec{1}\\
            G_0(v') - G_p(v) \succeq& \lambda^p \Lambda(Bv) \vec{1} + \frac{\lambda^{p+1}}{1 - \lambda} \Lambda(Bv) \vec{1} - \frac{\lambda^p}{1 - \lambda} \Lambda(Bv) \vec{1} = \vec{0}
        \end{align*}
        We already have $ G_{q-1}(v') \preceq G_{q}(v') $.
        \[
            Bv' = L\left[ L^{p+1}_{d_v}v \right] - L^{p+1}_{d_v}v
            \preceq L_{d_{v'}}\left[ L^{p+1}_{d_v}v - L^{p}_{d_v}v \right]
            = L_{d'_{v'}} \left[ \lambda^p \Upsilon(Bv) \right]
            = \lambda^{p+1} \Upsilon(Bv)\\
        \]
        \begin{align*}
            G^{p} (v) - G^{0}(v') =& \frac{\lambda^p}{1 - \lambda} \Upsilon(Bv) \vec{1} - \frac{1}{1 - \lambda} \Upsilon(Bv') \vec{1} - {(\lambda P_{d_v})}^p Bv\\
            \succeq& \frac{\lambda^p}{1 - \lambda} \Upsilon(Bv) \vec{1} - \frac{\lambda^{p+1}}{1 - \lambda} \Upsilon(Bv)\vec{1} - \lambda^{p} \Upsilon(Bv) \vec{1} = \vec{0}
        \end{align*}
    \end{proof}
\end{proposition}

\begin{align*}
    &r(s,a') + \sum^{}_{s' \in S} \lambda p(s' | s,a') G^{m_{n+1}}(v^{n+1}) \\
    \preceq& r(s,a') + \sum^{}_{s' \in S} \lambda p(s' | s,a') G^{m_{n}}(v^n) \\
    \preceq& G_{m_{n}}(v^n) \preceq G_{m_{n+1}}(v^{n+1})
\end{align*}

Which means that it's safty to eliminate nonoptimal action $ a' $ in step n.

Another complicate criterion is (without proof)
\begin{theorem}
    Let $ \left\{ v^n \right\} $ be generated by modified policy iteration, and let $ d_{n+1} $ be any $ v^{n+1} $-improving decision rule. Then $ d_{n+1}(s) $ will note equal $ a' $ if, for some $ v \le n $,
    \[
        r(s,a') + \sum^{}_{s' \in S}  \lambda p(s' | s, a') v^{\nu}(s') + \lambda \sum^{n}_{k = \nu} \Upsilon(v^{k+1} - v^{k}) - v^{n+1}(s) < \lambda^{m_n + 1} \Lambda(P^{m_n}_{d_{v^n}} B v^n)
    \]
\end{theorem}

\subsubsection{Modified Policy Iteration with Action Elimination and an Improved Stopping Criterion}%
\label{ssub:modified_policy_iteration_with_action_elimination_and_an_improved_stopping_criterion}

\subsubsection{Numerical Performance of Modified Policy Iteration with Action Elimination}%
\label{ssub:numerical_performance_of_modified_policy_iteration_with_action_elimination}

\subsection{CONVERGENCE OF POLICIES， TURNPIKES，AND PLANNING HORIZONS}%
\label{sub:convergence_of_policies_turnpikes_and_planning_horizons}

Up to now, we focused on properties of sequences of values $ \left\{ v^n \right\} $. Then we study the correspongding decision rules $ \left\{ D_n \right\} $ where
\[
    D_n = \left\{ d \in D: r_d + \lambda P_d v^n = \max_{d \in D} \left\{ r_d + \lambda P_d v^n \right\} \right\}
\]

Let $ D^* = \left\{ d \in D: r_d + \lambda P_{d} v^*_{\lambda} = \max_{d' \in D} \left\{ r_{d'} + \lambda P_{d'} v^*_{\lambda} \right\} \right\} $.
In this section, we let $ \left\{ v^n \right\} $ be the sequences of value iteration's sequence.

\begin{theorem}
    Suppose S and $ A_S $ are finite. Then for any $ v^0 \in V $, there exists an $ n^* $ such that, for all $ n \ge n^* $, $ D_{n} \subset D^* $. If $ D^* = D, n^* = 0 $. Otherwise,
    \[
        n^* \le \left\lfloor \frac{\log(\lambda^{-1}(1-\lambda)c) - \log(sp(Bv^0))}{\log(\lambda \gamma)}  \right\rfloor^{+} + 1,
        \quad 
        c = \inf_{d \in D\slash D^*} \Arrowvert v^*_{\lambda} - L_{d}v^{*}_{\lambda} \Arrowvert_{\infty} > 0
    \]
    \begin{proof}
        \[
            v_n^L = v^n + {(1 - \lambda)}^{-1} \Lambda(Bv^n) \vec{1} \preceq v^*_{\lambda} \preceq
            v^n + {(1 - \lambda)}^{-1}\Upsilon(Bv^n) \vec{1} = v^{U}_n
        \]
        \begin{align*}
            &v^*_{\lambda} - L_{d_n} v^*_{\lambda} \preceq v^{U}_{n+1} - L_{d_n}v^L_{n}\\
            =& v^{n+1} + {(1 - \lambda)}^{-1} \Upsilon(Bv^{n+1}) \vec{1}
            - L_{d_n}\left[ v^n + {(1 - \lambda)}^{-1} \Lambda(B v^{n})\vec{1} \right]\\
            \preceq& \lambda {(1 - \lambda)}^{-1}\left[ \Upsilon(B v^n) - \Lambda(Bv^n) \right] \vec{1}\\
            &v^*_{\lambda} - L_{d_n} v^*_{\lambda} \succeq v^{L}_{n+1} - L_{d_n}v^U_{n}\\
            =& v^{n+1} + {(1 - \lambda)}^{-1} \Lambda(Bv^{n+1}) \vec{1}
            - L_{d_n}\left[ v^n + {(1 - \lambda)}^{-1} \Upsilon(B v^{n})\vec{1} \right]\\
            \succeq& \lambda {(1 - \lambda)}^{-1}\left[ \Lambda(B v^n) - \Upsilon(Bv^n) \right] \vec{1}\\
            &\Arrowvert v^*_{\lambda} - L_{d_n} v^*_{\lambda}  \Arrowvert_\infty 
            \le \lambda{(1-\lambda)}^{-1} sp(Bv^n) \vec{1}
        \end{align*}
        Then if $ \lambda{(1-\lambda)}^{-1} sp(Bv^n) \vec{1} < c \vec{1} $, we can guarantee that  $ \forall d_n \in D_n$, $ \Arrowvert v^*_{\lambda} - L_{d_n} v^*_{\lambda} \Arrowvert_{\infty} < c \Rightarrow D_n \subset D^* $. Furthermore, we already have
        \[
            sp(B v^n) \le {(\lambda \gamma)}^{n} sp(B v^0)
        \]
        we can let $ n^* $ satisfies
        \[
            {(\lambda \gamma)}^{n^*} sp(Bv^0) \le \frac{1 - \lambda}{\lambda} c \Rightarrow
            n^{*} \ge \frac{\log(\lambda^{-1}(1 - \lambda)c) - \log(sp(Bv^0))}{\log(\lambda\gamma)} 
        \]
        We refine our proof: $ n^* \ge \frac{\log(\lambda^{-1}(1 - \lambda)c) - \log(sp(Bv^0))}{\log(\lambda\gamma)} $ is sufficient to guarantee that $ \forall n \ge n^* $, $ D_n \subset D^* $.
    \end{proof}
\end{theorem}

This bound may be quite large when $ \lambda \rightarrow 1 $.

\begin{lemma}
    \[
        \gamma = \max_{s \in S, a \in A_s, s' \in S, a' \in A_{s'}} \left[ 1 - \sum^{}_{j\in S} \min \left[ p(j|s,a), p(j|s, a') \right]  \right]
    \]
    Then, for any $ u \in V, d \in D $ and $ d' \in D $
    \[
        -\gamma sp(u) \vec{1} \preceq P_d u - P_{d'}u \preceq \gamma sp(u) \vec{1}
    \]
    \begin{proof}
        \begin{align*}
            P_d u - P_{d'}u \preceq sp\left( 
                \begin{bmatrix}
                P_d \\
                P_{d'}
                \end{bmatrix} u \right) \vec{1}
                \preceq \gamma_d sp(u) \vec{1} \preceq \gamma sp(u) \vec{1}
        \end{align*}
    \end{proof}
\end{lemma}

\begin{proposition}
    Another sufficient bound
    \[
        n^* \ge \frac{ \log(c) - \log(sp(v^*_\lambda - v^0))}{ \log (\lambda \gamma)} 
    \]
    \begin{proof} $ \forall d_n \in D_n $,
        \begin{align*}
            Lv^{*}_{\lambda} - L_{d_n} v^{*}_{\lambda}
            =& L\left[ v^n + (v^*_{\lambda} - v^n) \right] - L_{d_n}\left[ v^n + (v^*_{\lambda} - v^n) \right]\\
            =& L_{d^*} v^n - L_{d_n} v^n + \lambda P_{d^*} (v^{*}_{\lambda} - v^n) - \lambda P_{d_n} (v^*_{\lambda} - v^n)\\
            \preceq& L_{d^*}v^n - L_{d_n} v^n + \lambda \gamma sp(v^*_{\lambda} - v^n)\\
            \preceq&  L_{d^*}v^n - L_{d_n} v^n + {(\lambda \gamma)}^{n+1} sp(v^*_{\lambda} - v^0)\\
            \preceq& {(\lambda \gamma)}^{n+1} sp(v^*_{\lambda} - v^0)
        \end{align*}
        \begin{align*}
            Lv^{*}_{\lambda} - L_{d_n} v^{*}_{\lambda}
            =& L\left[ v^*_{\lambda} + (v^n - v^*_{\lambda}) \right] - L_{d_n}\left[ v^*_{\lambda} + (v^n - v^*_{\lambda}) \right]\\
            =& L_{d^*} v^*_\lambda - L_{d_n} v^{*}_{\lambda} + \lambda P_{d^*} ( v^n - v^{*}_{\lambda}) - \lambda P_{d_n} ( v^n - v^*_{\lambda})\\
            \succeq& L_{d^*}v^*_{n} - L_{d_n} v^*_{n} - \lambda \gamma sp(v^n - v^*_{\lambda})\\
            \succeq&  L_{d^*}v^n - L_{d_n} v^n - {(\lambda \gamma)}^{n+1} sp(v^*_{\lambda} - v^0)\\
            \succeq& - {(\lambda \gamma)}^{n+1} sp(v^*_{\lambda} - v^0)\\
        \end{align*}
        We want $ \forall d_n \in D_n $, $ v^*_{\lambda} - L_{d_n} v^*_{\lambda} \le c \vec{1} $, let
        \[
            {(\lambda \gamma)}^{n^*+1} sp(v^*_{\lambda} - v^0) \le c
            \Rightarrow n^* \ge  \frac{\log c - \log(sp(v^*_{\lambda} - v^0))}{ \log(\lambda \gamma)} - 1
        \]
    \end{proof}
\end{proposition}
