\relax 
\providecommand\tcolorbox@label[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Dynamic Programming}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Neural Network Architectures and Training}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Stochastic Iterative Algorithms}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}THE BASIC MODEL}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}CONVERGENCE BASED ON A SMOOTH POTHENTIAL FUNCTION}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Convergence Proofs}{5}}
\newlabel{ssub:convergence_proofs}{{4.2.1}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Sinulation Methods for a Lookup Table Representation}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}SOME ASPECTS OF MONTE CARLO SIMULATION}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}POLICY EVALUATION BY MONTE CARLO SIMULATION}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Q-Factors and Policy Iteration}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}TEMPORAL DIFFERENCE METHODS}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Approximate DP with Cost-to-Go Function Approximation}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}GENERRIC ISSUES-FROM PARAMETERS TO POLICIES}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}APPROXIMATE POLICY ITERATION}{9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.1}Approximate Policy Iteration Based on Monte Carlo Simulation}{9}}
