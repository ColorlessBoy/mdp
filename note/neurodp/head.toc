\contentsline {section}{\numberline {1}Introduction}{2}
\contentsline {section}{\numberline {2}Dynamic Programming}{2}
\contentsline {section}{\numberline {3}Neural Network Architectures and Training}{2}
\contentsline {section}{\numberline {4}Stochastic Iterative Algorithms}{2}
\contentsline {subsection}{\numberline {4.1}THE BASIC MODEL}{3}
\contentsline {subsection}{\numberline {4.2}CONVERGENCE BASED ON A SMOOTH POTHENTIAL FUNCTION}{3}
\contentsline {subsubsection}{\numberline {4.2.1}Convergence Proofs}{5}
\contentsline {section}{\numberline {5}Sinulation Methods for a Lookup Table Representation}{6}
\contentsline {subsection}{\numberline {5.1}SOME ASPECTS OF MONTE CARLO SIMULATION}{6}
\contentsline {subsection}{\numberline {5.2}POLICY EVALUATION BY MONTE CARLO SIMULATION}{7}
\contentsline {subsubsection}{\numberline {5.2.1}Q-Factors and Policy Iteration}{8}
\contentsline {subsection}{\numberline {5.3}TEMPORAL DIFFERENCE METHODS}{8}
\contentsline {section}{\numberline {6}Approximate DP with Cost-to-Go Function Approximation}{8}
\contentsline {subsection}{\numberline {6.1}GENERRIC ISSUES-FROM PARAMETERS TO POLICIES}{9}
\contentsline {subsection}{\numberline {6.2}APPROXIMATE POLICY ITERATION}{9}
\contentsline {subsubsection}{\numberline {6.2.1}Approximate Policy Iteration Based on Monte Carlo Simulation}{9}
