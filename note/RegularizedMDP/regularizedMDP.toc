\contentsline {section}{\numberline {1}Regularized MDPs}{2}
\contentsline {section}{\numberline {2}Negative entropy}{4}
\contentsline {section}{\numberline {3}Regularized Modified Policy Iteration}{4}
\contentsline {subsection}{\numberline {3.1}Analysis}{4}
\contentsline {section}{\numberline {4}Mirror Descent Modified Policy Iteration}{5}
\contentsline {section}{\numberline {5}Error Bounds for Approximate Policy Iteration}{5}
\contentsline {subsection}{\numberline {5.1}KEY BOUND THEOREM}{5}
\contentsline {subsection}{\numberline {5.2}APPROXIMATE POLICY EVALUATION}{6}
\contentsline {subsubsection}{\numberline {5.2.1}Linear Feature-based approximation}{6}
\contentsline {subsubsection}{\numberline {5.2.2}The Quadratic Residual Soluction}{7}
\contentsline {subsubsection}{\numberline {5.2.3}Temporal Difference Solution}{8}
\contentsline {section}{\numberline {6}Finite-Time Bounds for Fitted Value Iteration}{8}
\contentsline {subsection}{\numberline {6.1}Approximating the Bellman Operator}{8}
\contentsline {subsection}{\numberline {6.2}MAIN RESULT}{9}
\contentsline {section}{\numberline {7}Approximate Modified Policy Iteration}{10}
\contentsline {subsection}{\numberline {7.1}Approximate MPI Algorithms}{10}
\contentsline {subsection}{\numberline {7.2}Error Propagation}{10}
