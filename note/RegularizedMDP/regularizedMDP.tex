\documentclass[a4paper]{article}

\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{tcolorbox}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}

% newtheorem
\newtheorem{assumption}{Assumption}
\newtheorem{conjecture}{Conjecture}
\newtheorem{corollary}{Corollary}
\newtheorem{claim}{Claim}
\newtheorem{example}{Example}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{remark}{Remark}
\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}

\title{A Theory of Regularized MDPs}
\author{Peng Lingwei}
\begin{document}

\maketitle
\tableofcontents
\newpage

\section{Regularized MDPs}%

\begin{enumerate}
    \item Regularized function: $ \Omega(\pi) $ is strongly convex;
    \item Regularized value functions: $ V^{\pi, \Omega}(s) = V^{\pi} - \Omega(\pi(s))$
        \begin{align*}
            V^{\pi, \Omega}(s) =& \mathbb{E}^{\pi}\left[ \sum^{\infty}_{t=0} \gamma^t (r(S_t, A_t) - (1-\gamma)\Omega(\pi(s))) \vert S_0 = s \right] \\
            =& \mathbb{E}^{\pi}\left[ \sum^{\infty}_{t=0} \gamma^t (r(S_t, A_t)) \vert S_0 = s \right] - \sum^{\infty}_{t=0} (1-\gamma) \gamma^t \Omega(\pi(s)) \\
            =& V^{\pi}(s) - \Omega(\pi(s))
        \end{align*}
        In MDP, $ Q^{\pi}(s,a) = r(s,a) + \gamma \mathbb{E}_{P(s'|s,a)}\left[ V^{\pi}(s') \right] $. And $ V^{\pi} = T^{\pi}V^{\pi} = {\left( \langle \pi(s), Q^{\pi}(s, \cdot) \rangle \right)}_{s \in S} $. 
        Then,let $ Q^{\pi, \Omega}(s,a) = r(s,a) + \gamma \mathbb{E}_{P(s'|s,a)}\left[ V^{\pi, \Omega}(s') \right] $,
        \[
            V^{\pi, \Omega}(s) = \langle \pi(s), Q^{\pi, \Omega}(s, \cdot) \rangle - (1-\gamma)\Omega(\pi(s))
        \]
    \item Regularized optimal value function: $ V^{*, \Omega}(s) = \max_{\pi \in \Pi^{MR}} V^{\pi}(s) - \Omega(\pi(s)) $
        Let $ Q^{*, \Omega}(s, \cdot) = r(s,a) + \gamma \mathbb{E}_{P(s'|s,a)}\left[ V^{*,\Omega}(s') \right] $.
        \begin{align*}
            V^{*, \Omega}(s) =& \max_{\pi \in \Pi^{MR}} V^{\pi}(s) - \Omega(\pi(s))\\
            =& \max_{\pi \in \Pi^{MR}} \langle \pi(s), Q^{\pi, \Omega}(s, \cdot) \rangle- (1 - \gamma)\Omega(\pi(s))\\
            =& \max_{\pi \in \Pi^{MR}} \langle \pi(s), Q^{*, \Omega}(s, \cdot) \rangle- (1 - \gamma)\Omega(\pi(s)) \quad (\text{proof is trivial})\\
            =& \Omega^{*}_{\gamma}(Q^{*,\Omega}(s,\cdot))
        \end{align*}
        where $ \Omega_{\gamma}^{*} $ is Legendre-Fenchel transform of $ (1-\gamma)\Omega $. More specifically,
        \[
            \forall q_s \in \mathbb{R}^{\left| A \right|}, \Omega_{\gamma}^{*}(q_s) 
            = \max_{\pi \in \Pi^{MR}} \langle \pi_s, q_s \rangle - (1- \gamma) \Omega(\pi_s)
        \]
        
    \item Regularized Bellman operator: $ T^{\pi,\Omega}V = T^{\pi} V - (1-\gamma)\Omega(\pi)$\\
        \begin{itemize}
            \item Let $ Q_V(s,a) = r(s,a) + \gamma \mathbb{E}_{P(s'|s,a)}\left[ V(s') \right] $,
                \[
                    T^{\pi,\Omega}V (s) = \langle \pi_s, Q_V(s, \cdot) \rangle - (1 - \gamma)\Omega(\pi_s)
                \]
            \item Monotonicity:$ V_1 \succeq V_2 \Rightarrow T^{\pi, \Omega}V_1 \succeq T^{\pi, \Omega}V_2 $
                \[
                    T^{\pi, \Omega}V_1 - T^{\pi, \Omega}V_2 = T^{\pi}V_1 - T^{\pi}V_2 \succeq \vec{0}
                \]
            \item Distributivity: $ T^{\pi, \Omega}(V + c \vec{1}) =  T^{\pi, \Omega}(V) + \gamma c \vec{1} $
                \begin{align*}
                    T^{\pi, \Omega}(V + c \vec{1}) =& T^{\pi}(V + c \vec{1}) - (1-\gamma)\Omega(\pi) \\
                    =& T^{\pi}(V) + \gamma c \vec{1} - (1-\gamma)\Omega(\pi) = T^{\pi \Omega}V + \gamma c \vec{1}
                \end{align*}
                \item Contraction: $ \Arrowvert T^{\pi, \Omega}V_1 - T^{\pi, \Omega}V_2 \Arrowvert_{\infty} \le \gamma {\Arrowvert V_1 - V_2 \Arrowvert}_\infty $
                    \[
                        \Arrowvert T^{\pi, \Omega}V_1 - T^{\pi, \Omega}V_2 \Arrowvert_{\infty}
                        = \Arrowvert T^{\pi}V_1 - T^{\pi}V_2 \Arrowvert_{\infty}
                        \le \gamma \Arrowvert V_1 - V_2 \Arrowvert_{\infty}
                    \]
            \item $ T^{\pi,\Omega} $'s unique fixed point is $ V^{\pi, \Omega} $;
                \begin{align*}
                    T^{\pi, \Omega}V^{\pi, \Omega} =& T^{\pi}V^{\pi, \Omega} - (1 - \gamma) \Omega(\pi)\\
                    =& T^{\pi}\left( V^{\pi} - \Omega(\pi) \right) - (1 - \gamma) \Omega(\pi)\\
                    =& T^{\pi}(V^{\pi}) - \gamma \Omega(\pi) - (1-\gamma) \Omega(\pi)\\
                    =& V^{\pi} - \Omega(\pi) = V^{\pi, \Omega}
                \end{align*}
        \end{itemize}
    \item Regularized optimal Bellman operator: $ T^{*,\Omega}V = \max_{\pi \in \Pi^{MR}} T^{\pi,\Omega}V $;
        \begin{align*}
            T^{*,\Omega}V = \max_{\pi \in \Pi^{MR}} \langle \pi_s, Q_V(s, \cdot) \rangle - (1 - \lambda)\Omega(\pi_s)
            = \Omega^{*}_{\gamma}( Q_{V}(s,\cdot))
        \end{align*}
        \begin{itemize}
            \item Monotonicity: $ V_1 \succeq V_2 \Rightarrow T^{*,\Omega} V_1 \succeq T^{*, \Omega} V_2 $.\\
                Let $ V_1 $'s optimal policy be $ \pi_1 $, and $ V_2 $'s be $ \pi_2 $.
                \begin{align*}
                    T^{*,\Omega} V_1 - T^{*, \Omega} V_2 =& \max_{\pi \in \Pi^{MR}} T^{\pi,\Omega}V_1 -  \max_{\pi \in \Pi^{MR}} T^{\pi,\Omega}V_2\\
                    \succeq& T^{\pi_2, \Omega}V_1 - T^{\pi_2, \Omega}V_2 \succeq P^{\pi_2} (V_1 - V_2) \succeq \vec{0}
                \end{align*}
            \item Distributivity: $ T^{*,\Omega}(V + c \vec{1}) = T^{*, \Omega}V + \gamma c \vec{1} $.
            \item Contraction: $ {\Arrowvert T^{*, \Omega}V_1 - T^{*, \Omega}V_2 \Arrowvert}_\infty \preceq \gamma {\Arrowvert V_1 - V_2 \Arrowvert}_\infty $
                \begin{align*}
                    {\Arrowvert T^{*, \Omega}V_1 - T^{*, \Omega}V_2 \Arrowvert}_\infty
                    \le {\Arrowvert T^{\pi_1,\Omega} V_1 - T^{\pi_1, \Omega}V_2 \Arrowvert}_\infty
                    \le {\Arrowvert T^{\pi_1} V_1 - T^{\pi_1} V_2 \Arrowvert}_\infty
                    \le \gamma {\Arrowvert V_1 - V_2 \Arrowvert}_\infty
                \end{align*}
            \item $ T^{*, \Omega} $'s unique fixed point is $ V^{*,\Omega} $. (We talk about $ \sup $ instead of $ \min $)\\
                First we proof $ V \succeq T^{*,\Omega} V \Rightarrow V \succeq V^{*,\Omega}$:
                \begin{align*}
                    &\forall \pi, \quad 
                    V \succeq \sup_{\pi' \in \Pi^{MR}} T^{\pi', \Omega} V \succeq r^\pi + \gamma P^{\pi} V - (1-\gamma) \Omega(\pi)\\
                    \Rightarrow& V \succeq {(I - \gamma P^{\pi})}^{-1}(r^{\pi} - (1-\gamma)\Omega(\pi)) = V^{\pi,\Omega}
                    \quad \Rightarrow V \succeq V^{*, \Omega}
                \end{align*}
                Second we proof $ V \preceq T^{*,\Omega} V \Rightarrow V \preceq V^{*,\Omega}$:
                By definition of $ \sup $,
                \[
                    \forall \epsilon, \exists \pi \in \Pi^{MR}, V \preceq T^{\pi, \Omega}V + \epsilon \cdot \vec{1}
                    \Rightarrow V \preceq {(I - \lambda P^{\pi})}^{-1} [r^{\pi} - (1-\gamma)\Omega(\pi) + \epsilon \cdot \vec{1}] 
                \]
                \[
                    V \preceq {(I - \lambda P^{\pi})}^{-1} [r^{\pi} - (1-\gamma)\Omega(\pi)] + \frac{\epsilon}{1 - \gamma} \vec{1} \preceq V^{*, \Omega} + \frac{\epsilon}{1 - \gamma} \vec{1}
                \]
        \end{itemize}
    \item Assume that $ \Omega_L \le \Omega \le \Omega_U $, then $ V^{\pi} - \Omega_U \le V^{\pi, \Omega} \le V^{\pi} - \Omega_L $.
        \[
             \max_{\pi \in \Pi^{MR}} V^{\pi} - \Omega_U \le \max_{\pi \in \Pi^{MR}} V^{\pi, \Omega} \le \max_{\pi \in \Pi^{MR}} V^{\pi} - \Omega_L \Rightarrow V^{*} - \Omega_U \le V^{*, \Omega} \le V^{*} - \Omega_L
        \]
        Furthermore,
        \begin{align*}
            &V^{*} \le V^{*, \Omega} + \Omega_U = V^{\pi^{*, \Omega}, \Omega} + \Omega_U \le V^{\pi^{*,\Omega}} + \Omega_U - \Omega_L \\
            \Rightarrow& V^* - \left( \Omega_U - \Omega_L \right) \le V^{\pi^{*, \Omega}} \le V^{*}
        \end{align*}
\end{enumerate}

\section{Negative entropy}%

A classical example is the negative entropy $ \Omega(\pi_s) = {(1 - \gamma)}^{-1}\sum^{}_{a} \pi_s(a) \ln \pi_s(a) $.

\begin{align*}
    \Omega^{*}_{\gamma}(q_s) =& \max_{\pi \in \Pi^{MR}} \langle \pi_s, q_s \rangle - \sum^{}_{a} \pi_s(a) \ln \pi_s(a)\\
\end{align*}

We change it into 
\begin{align*}
    -\Omega^{*}_{\gamma}(q_s) =& \min_{\pi_{s} \succeq \vec{0}} \max_{\alpha \ne 0} \alpha \left(\sum^{}_{a} \pi_s(a) - 1 \right)-\langle \pi_s, q_s \rangle + \sum^{}_{a} \pi_s(a) \ln \pi_s(a)\\
    =& \max_{\alpha \ne 0} \min_{\pi_s \succeq \vec{0}} \alpha \left(\sum^{}_{a} \pi_s(a) - 1 \right)-\langle \pi_s, q_s \rangle + \sum^{}_{a} \pi_s(a) \ln \pi_s(a)\\
    \Rightarrow&  \alpha - q_s(a) + \ln \pi_{s}(a) + 1 = 0,\quad \sum^{}_{a} \pi_{s}(a) = 1 \\
    \Rightarrow& \sum^{}_{a} \exp\left\{ -1 + q_{s}(a) - \alpha \right\} = 1
    \Rightarrow \alpha + 1 = \ln \sum^{}_{a} \exp\left\{ q_s(a) \right\}\\
    \Rightarrow& \pi_s(a) = \frac{\exp \left\{q_{s}(a) \right\}}{\sum^{}_{a} \exp\left\{ q_s(a) \right\}} 
\end{align*}
\[
    \Omega^{*}_{\gamma}(q_s) = \ln \sum^{}_{a} \exp q_s(a) \Rightarrow \nabla \Omega^*_{\gamma}(q_s) = \frac{\exp\left\{ q_s(a) \right\}}{ \sum^{}_{a} \exp\left\{ q_s(a) \right\}} = \pi^*_s(a)
\]

\section{Regularized Modified Policy Iteration}%

\begin{definition}
    \textbf{(Regularized modified policy iteration).}
    \[
        \pi_{k+1} = \arg\max_{\pi_{k} \in \Pi^{MR}} T_{\pi,\Omega}V_{k}, \quad V_{k+1} = T^{m}_{\pi_{k+1}, \Omega} V_k
    \]
\end{definition}

Related algorithms:
\begin{enumerate}
    \item Soft Q-learning: $ \hat q_{k+1}(s,a) = r(s,a) + \gamma \mathbb{\hat E}_{s' | s,a} \left[ \Omega^*(q_k(s',\cdot)) \right] , J(\theta) = \mathbb{E} \left[ {\Arrowvert \hat q_{k+1} - q_{\theta} \Arrowvert}^2_2 \right]$
    \item {SAC}: $ \hat \pi_{k+1}(\cdot | s) = \nabla \Omega^*(q_k(s, \cdot)), \quad J(w) = \mathbb{\hat E} \left[ KL(\pi_{w}(\cdot | s_i) \Arrowvert \hat \pi_{k+1}(\cdot | s))\right]$
\end{enumerate}

\subsection{Analysis}%
Two errors is introduced in {AMPI}.
\begin{itemize}
    \item We only can get $\epsilon'_{k+1}$-optimal policy $ \pi'_{k+1} $: $T_{\pi_{k+1}, \Omega} V_k \preceq T_{\hat\pi_{k+1}, \Omega} V_k + \epsilon'_{k+1} $;
    \item $ V_{k+1} = T^m_{\hat\pi_{k+1}, \Omega} V_k + \epsilon_{k+1} $.
\end{itemize}

We want bound $ l_{k,\Omega} = V^{*, \Omega} - V^{\pi_k, \Omega} $. We also denote $ d_k = V^{*, \Omega} - V_k $ and $ b_k = V_k - T^{\pi_{k+1}, \Omega}V_k $.

Denote $ \frac{1}{q} + \frac{1}{q'} = 1 $, and
\[
    C^{i}_{q} = \frac{1 - \gamma}{\gamma^i} \sum^{\infty}_{j=i} \gamma^j \max_{\pi_1, \ldots, \pi_j} \Arrowvert \frac{\rho P_{\pi_1}P_{\pi_2}\ldots P_{\pi_j}}{\mu}  \Arrowvert_{q, \mu}
\]
\begin{itemize}
    \item $ l_{k,\Omega} \le 2 \sum^{k-1}_{i=1} \sum^{\infty}_{j=i} \Gamma^j \left| \epsilon_{k-i} \right| + \sum^{k-1}_{i=0} \sum^{\infty}_{j=i} \Gamma^{i} \left| \epsilon'_{k-i} \right| + 2\sum^{\infty}_{j=k} \Gamma^{j} \min\left\{ \left| d_0 \right|, \left| b_0 \right| \right\}$;
    \item $ \Arrowvert l_{k,\Omega} \Arrowvert_{p,\rho} \le 2 \sum^{k-1}_{i=1} \frac{\gamma^i}{1 - \gamma} {(C^{i}_q)}^{\frac{1}{p} } \Arrowvert \epsilon_{k-i} \Arrowvert_{pq', \mu} + \sum^{k-1}_{i=0} \frac{\gamma^i}{1 - \gamma} {(C^{i}_{q})}^{\frac{1}{p} } \Arrowvert \epsilon'_{k-i} \Arrowvert_{pq', \mu} + \frac{2\gamma^{k}}{1 - \gamma} {(C^{i}_{q})}^{\frac{1}{p} } \min ( \Arrowvert d_0 \Arrowvert_{pq',\mu}, \Arrowvert b_0 \Arrowvert_{pq',\mu})$
\end{itemize}
The bound does no explain the good empirical results of related algorithms.

\section{Mirror Descent Modified Policy Iteration}%

\begin{itemize}
    \item $ \Omega_{\pi'_{s}}(\pi_s) = D_{\Omega}(\pi_s \Arrowvert \pi'_{s}) = \Omega(\pi_s) - \Omega(\pi'_s) - \langle \nabla \Omega(\pi'_s), \pi_s - \pi'_s \rangle $;
    \item $ \pi_{k+1} = \arg\max_{\pi} \langle q_k, \pi \rangle - D_{\Omega}(\pi \Arrowvert \pi_k) $;
\end{itemize}

\begin{definition}
    \textbf{(Mirror Descent MPI).}
    \begin{enumerate}
        \item Type1: $ \pi_{k+1} = \arg\max_{\pi} T_{\pi, \Omega_{\pi_k}}V_k, V_{k+1}=T^{m}_{\pi_{k+1}, \Omega_{\pi_k}}V_k $;
        \item Type2: $ \pi_{k+1} =  \arg\max_{\pi} T_{\pi, \Omega_{\pi_k}}V_k, V_{k+1}=T^{m}_{\pi_{k+1}, \Omega_{\pi_{k+1}}}V_k = T^{m}_{\pi_{k+1}} V_k $.
    \end{enumerate}
\end{definition}
The tool used to analyse error bound is very complicated.

\section{Error Bounds for Approximate Policy Iteration}%

\subsection{KEY BOUND THEOREM}%

\begin{enumerate}
    \item $ e_k = V_k - V^{\pi_k} $
    \item $ g_k = V^{\pi_{k+1}} - V^{\pi_k} $
    \item $ l_k = V^* - V^{\pi_k} $
    \item $ b_k = V_k - T^{\pi_k} V_k $
        \item $ \pi_{k+1} = \max_{\pi} T^{\pi} V_k $
\end{enumerate}
Target: bound $ l_k $.
\begin{lemma}
    \[
        l_{k+1} \preceq \gamma P^{\pi^*}l_k + \gamma \left\{  P^{\pi_{k+1}}{( I - \gamma P^{\pi_{k+1}})}^{-1}  - P^{\pi^*} {(I - \gamma P^{\pi_k})}^{-1}\right\} b_k
    \]
    \[
        l_{k+1} \preceq \gamma P^{\pi^*} l_k + \gamma \left\{ P^{\pi_{k+1}}{( I - \gamma P^{\pi_{k+1}})}^{-1} (I - \gamma P^{\pi_k}) - P^{\pi^*} \right\} e_k
    \]
    
    \begin{proof}
        \begin{align*}
            g_k =& T^{\pi_{k+1}} V^{\pi_{k+1}} - T^{\pi_{k+1}} V^{\pi_k} + T^{\pi_{k+1}} V^{\pi_k} - T^{\pi_{k+1}}V_k\\
            & + T^{\pi_{k+1}} V_k - T^{\pi_k} V_k + T^{\pi_k} V_k - T^{\pi_k} V^{\pi_k} \\
            \succeq& \gamma P^{\pi_{k+1}} (V^{\pi_{k+1}} - V^{\pi_k}) + \gamma P^{\pi_{k+1}}(V^{\pi_k} - V_k) + \gamma P^{\pi_k}(V_k - V^{\pi_k}) \\
            \succeq& - \gamma {(I - \gamma P^{\pi_{k+1}})}^{-1} (P^{\pi_{k+1}} - P^{\pi_k})e_k
        \end{align*}
        \begin{align*}
            e_k - g_k \preceq& \left[ I + \gamma {(I - \gamma P^{\pi_{k+1}})}^{-1} (P^{\pi_{k+1}} - P^{\pi_k}) \right] e_k\\
            =& {(I - \gamma P^{\pi_{k+1}})}^{-1} (I - \gamma P^{\pi_k}) e_k
        \end{align*}
        \begin{align*}
            l_{k+1} =& T^{\pi^*} V^* - T^{\pi^*} V^{\pi_k} + T^{\pi^*} V^{\pi_k} - T^{\pi^*} V_k + T^{\pi^*} V_k - T^{\pi_{k+1}}V_k \\
            &+ T^{\pi_{k+1}}V_k - T^{\pi_{k+1}}V^{\pi_k} + T^{\pi_{k+1}}V^{\pi_k} - T^{\pi_{k+1}} V^{\pi_{k+1}} \\
            \preceq& \gamma P^{\pi^*} (V^{*} - V^{\pi_k}) + \gamma P^{\pi^*}(V^{\pi_k} - V_k) + \gamma P^{\pi_{k+1}} (V_k - V^{\pi_k}) + \gamma P^{\pi_{k+1}} (V^{\pi_k} - V^{\pi_{k+1}})\\
            =& \gamma P^{\pi^*} l_k  + \gamma (P^{\pi_{k+1}} - P^{\pi^*}) e_k - \gamma P^{\pi_{k+1}} g_k\\
            \preceq& \gamma P^{\pi^*} l_k + \gamma \left\{ P^{\pi_{k+1}}{( I - \gamma P^{\pi_{k+1}})}^{-1} (I - \gamma P^{\pi_k}) - P^{\pi^*} \right\} e_k
        \end{align*}
        For $ (I - \gamma P^{\pi_k})e_k = b_k $,
        \[
            l_{k+1} \preceq \gamma P^{\pi^*}l_k + \gamma \left\{  P^{\pi_{k+1}}{( I - \gamma P^{\pi_{k+1}})}^{-1}  - P^{\pi^*} {(I - \gamma P^{\pi_k})}^{-1}\right\} b_k
        \]
    \end{proof}
\end{lemma}
\begin{theorem}
    \[
        \limsup_{k \rightarrow \infty} \Arrowvert V^* - V^{\pi_k} \Arrowvert_{\mu_0}
        \le \limsup_{k \rightarrow \infty}\gamma \mu_0 {(I - \gamma P^{\pi^*})}^{-1} \left\{  P^{\pi_{k+1}}{( I - \gamma P^{\pi_{k+1}})}^{-1} + P^{\pi^*} {(I - \gamma P^{\pi_k})}^{-1}\right\} \left| b_k \right|
    \]
    \[
        \limsup_{k \rightarrow \infty} \Arrowvert V^* - V^{\pi_k} \Arrowvert_{\mu_0}
        \le \limsup_{k \rightarrow \infty}\gamma \mu_0 {(I - \gamma P^{\pi^*})}^{-1} \left\{ P^{\pi_{k+1}}{( I - \gamma P^{\pi_{k+1}})}^{-1} (I + \gamma P^{\pi_k}) + P^{\pi^*} \right\} \left| e_k \right|
    \]
    After normalization,let
    \[
        Q_k = \frac{{(1 - \gamma)}^2}{2}  {(I - \gamma P^{\pi^*})}^{-1} \left\{  P^{\pi_{k+1}}{( I - \gamma P^{\pi_{k+1}})}^{-1} + P^{\pi^*} {(I - \gamma P^{\pi_k})}^{-1}\right\},
    \]
    and
    \[
        \tilde Q_k = \frac{{(1 - \gamma)}^{2}}{2} {(I - \gamma P^{\pi^*})}^{-1} \left\{ P^{\pi_{k+1}}{( I - \gamma P^{\pi_{k+1}})}^{-1} (I + \gamma P^{\pi_k}) + P^{\pi^*} \right\}.
    \]
    Then, write $ \mu_k = \mu_0 Q_k $ and $ \tilde \mu_k = \mu_0 \tilde Q_k $, we have
    \[
        \limsup_{k \rightarrow \infty} \Arrowvert V^* - V^{\pi_k} \Arrowvert_{\mu_0} \le \frac{2\gamma}{{(1 - \gamma)}^{2}}  \limsup_{k \rightarrow \infty} \Arrowvert V_k - T^{\pi_k } V_k \Arrowvert_{\mu_k}
    \]
    \[
        \limsup_{k \rightarrow \infty} \Arrowvert V^* - V^{\pi_k} \Arrowvert_{\mu_0} \le \frac{2 \gamma}{{(1 - \gamma)}^{2}} \limsup_{k \rightarrow \infty} \Arrowvert V_k - V^{\pi_k} \Arrowvert_{\tilde \mu_k}
    \]
\end{theorem}

\subsection{APPROXIMATE POLICY EVALUATION}%

\subsubsection{Linear Feature-based approximation}%
\begin{enumerate}
    \item Monte-Carlo simulations and regression: $ \min_{\theta} \Arrowvert \Phi \theta - V^{\pi_k}  \Arrowvert^2_{\rho_k} $;
    \item Minimal quadratic residual solution: $ \min_{\theta} \Arrowvert V_{\theta} - T^{\pi_k} V_{\theta} \Arrowvert^2_{\rho_k} $;
        \[
            A \theta = b\ with\ 
            \begin{cases}
                A = \Phi^T{(I - \gamma P^{\pi_k})}^{T} D_{\rho_k} (I - \gamma P^{\pi_k})\Phi\\
                b = \Phi^T{(I - \gamma P^{\pi_k})}^{T} D_{\rho_k} r^{\pi_k}
            \end{cases}
        \]
    \item Temporal Difference solution: $ \min_{\theta} \Arrowvert V_\theta - \Pi_{\pi_k} T^{\pi_k} V_{\theta} \Arrowvert^2_{\rho_k} $. For $ TD(0) $:
        \[
            A \theta = b\ with\ 
            \begin{cases}
                A = \Phi^T D_{\rho_k} (I - \gamma P^{\pi_k}) \Phi\\
                b = \Phi^T D_{\rho_k} r^{\pi_k}
            \end{cases}
        \]
\end{enumerate}

Because these method depends on the distribution $ \rho_k $ used in the minimization problem, which usually depends on the policy $ \pi_k $, therefore we have to consider the choice of $ \rho_k $.
\begin{itemize}
    \item Steady-state distribution $ \bar\rho_{\pi_k} $: $ \bar\rho_{\pi_k} = \bar\rho_{\pi_k} P^{\pi_k} $;
    \item Constant distribution $ \rho_0 $;
    \item  Mixed distribution $ \rho^{\lambda}_{\pi_k} = \rho_0{( I - \lambda P^{\pi_k})}^{-1}(1 - \lambda) $;
    \item Convex combination mixed distribution: $ \rho^{\delta}_{\pi_k} = (1 - \delta) \rho_0 + \delta \bar \rho_{\pi_k} $.
\end{itemize}
\begin{assumption}
    \[
        \inf_{\theta} \Arrowvert V_{\theta} - V^{\pi} \Arrowvert_{\rho_{\pi}} \le \epsilon
    \]
\end{assumption}

\subsubsection{The Quadratic Residual Soluction}%

\[
    \Arrowvert V_k - T^{\pi_{k}} V_{k} \Arrowvert_{\rho_k} = \inf_{\theta} \Arrowvert V_{\theta} - T^{\pi_k} V_{\theta} \Arrowvert_{\rho_k} = \inf_{\theta} \Arrowvert (I - \gamma P^{\pi_k})(V_{\theta} - V^{\pi_k}) \Arrowvert_{\rho_k} \le \Arrowvert I - \gamma P^{\pi_k} \Arrowvert_{\rho_k} \epsilon
\]
\[
    \Arrowvert V_k - T^{\pi_k} V_k \Arrowvert^2_{\mu_k} \le {\Arrowvert \mu_k / \rho_k \Arrowvert}_\infty \Arrowvert V_k - T^{\pi_k} V_k \Arrowvert^2_{\rho_k}
\]

So we need a new assumption.
\begin{assumption}
\[
    \forall \pi, \exists \mu,C, have\ P^{\pi}(i,j) \le C \mu(j).
\]
If $ \bar\mu(j) = 1/N $ and $ C = N $, it always satisfies. However, we are actually interested in finding a constant $ C \ll N $.
\end{assumption}

\begin{lemma}
    In preceeding section, $ \mu_k = \mu_0 Q_k $. If assumption2 exists, we have $ \mu_k \le C \mu $.
    \begin{proof}
        $ (P_1 P_2)(i,j) = \sum^{}_{k} P_1(i,k) P_2(k,j) \le C \mu(j) \sum^{}_{k} P_1(i,k) = C\mu(j) $. So $ Q_k(i,j) \le C \mu(j) \Rightarrow \mu_k(j) \le C\mu(j)$
    \end{proof}
\end{lemma}
\begin{theorem}
    Assume two assumption hold with some distribution $ \mu_0 $ and $ C $.
    \begin{itemize}
        \item $ \rho^{\lambda}_{\pi_k} = \mu_0 {(I - \lambda P^{\pi_k})}^{-1}(1-\lambda) $, then
            \[
               \limsup {\Arrowvert V^* - V^{\pi_k} \Arrowvert}_\infty \le \frac{2\gamma}{{(1 - \gamma)}^{2}} \sqrt{\frac{C}{1 - \lambda} } \left( 1 + \gamma\sqrt{\min\left( \frac{C}{1 - \lambda} , \frac{1}{\lambda}  \right)} \right) \epsilon  
            \]
        \item $ \rho^{\delta}_{\pi_k} = (1 - \delta) \mu_0 + \delta \bar\rho_{\pi_k} $.
            \[
                \limsup {\Arrowvert V^* - V^{\pi_k} \Arrowvert}_\infty \le \frac{2\gamma}{{(1 - \gamma)}^{2}} \sqrt{\frac{C}{1 - \delta} }(1 + \gamma \sqrt C) \epsilon
            \]
    \end{itemize}
    \begin{proof}
        \begin{enumerate}
            \item $ \rho^{\lambda}_{k} \succeq (1 - \lambda)\mu_0 $ and $ \rho^{\delta}_{k} \ge (1 - \delta) \mu_0 $.
            \item $ \Arrowvert P^{\pi_k} \Arrowvert^{2}_{\rho^\lambda_k} \le \min\left( \frac{C}{1 - \lambda}, \frac{1}{\lambda}  \right) $:
                \[
                    \Arrowvert P^{\pi_k} h \Arrowvert^2_{\rho^{\lambda}_{k}} = \rho^{\lambda}_{k} {(P^{\pi_k} h)}^{2} \le \rho^{\lambda}_{k} P^{\pi_k}h^2 \le C \mu_0 h^2 \le \frac{C}{1 - \lambda} \rho^{\lambda}_{k}h^2 = \frac{C}{1 - \lambda} \Arrowvert h \Arrowvert^2_{\rho^{\lambda}_{k}}
                \]
                \begin{align*}
                    \Arrowvert P^{\pi_k} h \Arrowvert^2_{\rho^{\lambda}_{k}}
                    =& (1 - \lambda) \mu_0 \sum^{\infty}_{t=0} \lambda^t {(P^{\pi_k})}^{t} {{P^{\pi_k}h}}^{2}
                    \le (1 - \lambda) \mu_0 \sum^{\infty}_{t=0} \lambda^{t} {(P^{\pi_k})}^{t+1} h^2\\
                    =& \frac{1 - \lambda}{\lambda} \mu_0 \left\{ \sum^{\infty}_{t=0} \lambda^t {(P^{\pi_k})}^{t} h^2 - h^2 \right\} \le \frac{1}{\lambda} \rho^{\lambda}_{k}h^2 = \frac{1}{\lambda} \Arrowvert h \Arrowvert^2_{\rho^\lambda_{k}}
                \end{align*}
            \item $ \Arrowvert P^{\pi_k} \Arrowvert^2_{\rho^{\delta}_k} \le C $.
                \begin{align*}
                    \Arrowvert P^{\pi_k} h \Arrowvert^2_{\rho^{\delta}_k}
                    =& \rho^{\delta}_{k} {(P^{\pi_k h})}^2
                    \le (1 - \delta) \mu_0 P^{\pi_k} h^2 + \delta \bar\rho_{\pi_k} P^{\pi_k}h^2
                    \le C(1 - \delta) \mu_0 h^2 + \delta \bar\rho_k h^2\\
                    =& C (\rho^{\delta} _ k - \delta \bar \rho_k) h^2 + \delta \bar\rho_k h^2
                    \le C \rho^{\delta}_{k}h^2
                \end{align*}
            \item 
                \begin{align*}
                    \limsup_{k \rightarrow\infty} \Arrowvert l_k \Arrowvert_{\mu_0}
                    \le& \frac{2\gamma}{{(1 - \gamma)}^{2}} \limsup_{k \rightarrow\infty} \sqrt {{\Arrowvert \mu_k / \rho_k \Arrowvert}_\infty} \Arrowvert I - \gamma P^{\pi_k} \Arrowvert_{\rho_{\pi_k}}\epsilon\\
                    \le&  \frac{2\gamma}{{(1 - \gamma)}^{2}} \limsup_{k \rightarrow\infty} \sqrt {{\Arrowvert \mu_k / \rho_k \Arrowvert}_\infty} \left( 1 + \gamma \Arrowvert P^{\pi} \Arrowvert_{\rho_{\pi_k}} \right)\epsilon\\
                \end{align*}
        \end{enumerate}
    \end{proof}
\end{theorem} 
\subsubsection{Temporal Difference Solution}%
\begin{enumerate}
    \item 
        \begin{align*}
            &(I - \gamma \Pi_{\pi_k} P^{\pi_k}) (V_k - V^{\pi_k}) = V_k - \gamma \Pi_{\pi_k}P^{\pi_k}V_k - V^{\pi_k} + \gamma\Pi_{\pi_k}P^{\pi_k} V^{\pi_k} \\
            =& - V^{\pi_k} + \Pi_{\pi_k}(r^{\pi_k} + \gamma P^{\pi_k} V^{\pi_k}) = \Pi_{\pi_k}V^{\pi_k} - V^{\pi_k}
            := \epsilon'_k
        \end{align*}
\end{enumerate}
I lose my patience again.

\section{Finite-Time Bounds for Fitted Value Iteration}%

\subsection{Approximating the Bellman Operator}%

\begin{enumerate}
    \item Monte-Carlo estimate of $ TV_k $:
        \[
             \hat V(s) = \max_{a \in A} \frac{1}{M} \sum^{M}_{j=1} \left[ R_j(s, a) + \gamma V_k(s'_j) \right], s = 1, 2, \ldots, N
        \]
        \[
            V_{k+1} = \arg\min_{f \in \mathcal{F}} \Arrowvert f - \hat V \Arrowvert_p
        \]
    \item 
        \begin{align*}
            \mathbb{E}\left[ \hat V(s) \right] =& \mathbb{E}\left[ \max_{a \in A} \frac{1}{M} \sum^{M}_{j=1} \left[ R_j(s, a) + \gamma V_k(s'_j) \right] \right] \\
            \ge& \max_{a \in A} \mathbb{E} \left[ \frac{1}{M} \sum^{M}_{j=1} \left[ R_j(s,a) + \gamma V_k(s'_j) \right] \right] = TV_k
        \end{align*}
    \item Condition of $ \mathbb{P} \left\{ {\Arrowvert \hat V - TV \Arrowvert}_p \le \epsilon\right\} \ge 1 - \delta $
        \begin{proof}
            \begin{align*}
                \mathbb{P} \left\{ {\Arrowvert \hat V - \mathbb{E}\hat V \Arrowvert}_\infty \ge \epsilon \right\}
                \le 2 e^{-\frac{2M \epsilon^2}{{(R_{\max} + \gamma V_{\max})}^2} }
            \end{align*}
            It's easy to find function $ M \ge C_M(\epsilon, \delta) $, which guarantees
            \[
                 \mathbb{P} \left\{ \max_{\pi}{\Arrowvert \hat V - \mathbb{E} \hat V \Arrowvert}_\infty \ge \epsilon \right\} \le \delta
            \]
            Because $ \max_x f(x) - \max_x g(x) = f(x_f) - g(x_g) \le f(x_f) - g(x_f) \le \max_x (f(x) - g(x)) $,
            therefore
            \[
                \Arrowvert TV - \hat V \Arrowvert_p \le {\Arrowvert TV - \hat V \Arrowvert}_\infty \le \max_{\pi} {\Arrowvert \mathbb{E}\hat V - \hat V \Arrowvert}_\infty
            \]
        \end{proof}
    \item Condition of $ \mathbb{P} \left\{ \sup_{f \in \mathcal{F}} \left| \Arrowvert f - TV \Arrowvert_{p, \mu} - \Arrowvert f - TV \Arrowvert_{p, \hat \mu} \right| \le \epsilon \right\} \ge 1 - \delta $,
        where $ \Arrowvert f \Arrowvert^p_{p, \hat\mu} = \frac{1}{N} \sum^{N}_{i=1} \left| f_i \right|^{p} $. 
        ($ \hat \mu $ is sample distribution.)
        We can use Rademacher complexities to get function $ N \ge C_N(\epsilon, \delta) $ to guarantees these.
        The paper has some problem here, so I skip the proof.
        \begin{itemize}
            \item Rademacher complexity;
            \item Covering numbers.
        \end{itemize}
    \item We need bound $ \mathbb{P}\left\{ \Arrowvert V_{k+1} - TV_{k} \Arrowvert_{p, \mu} \le \epsilon \right\} \ge 1 - \delta $. (The preceeding conditions are sufficient.)
        \begin{align*}
            & \Arrowvert V_{k+1} - T V_{k} \Arrowvert_{p,\mu} \le \Arrowvert V_{k+1} - T V_{k} \Arrowvert_{p,\mu} + \epsilon \le \Arrowvert V_{k+1} - \hat V \Arrowvert_{p, \hat \mu} + 2\epsilon \le \inf_{f} \Arrowvert f - \hat V \Arrowvert_{p, \hat \mu} + 2\epsilon\\
            \le& \inf_{f} \Arrowvert f - T V \Arrowvert_{p, \hat \mu} + 3\epsilon
            \le \inf_{f} \Arrowvert f - T V \Arrowvert_{p, \mu} + 4\epsilon
        \end{align*}
\end{enumerate}
\subsection{MAIN RESULT}%

\begin{itemize}
    \item Single-sample: $ V_{k+1} = \arg\min_{f \in \mathbb{F}} \sum^{N}_{i=1} \left| f(s_i) - \max_{a \in A} \frac{1}{M} \sum^{M}_{j=1} \left[ R_j(s_i, a) + \gamma V_k(s'_j) \right] \right|^{p} $
    \item Multi-sample: $ V_{k+1} = \arg\min_{f \in \mathbb{F}} \sum^{N}_{i=1} \left| f(s^k_i) - \max_{a \in A} \frac{1}{M} \sum^{M}_{j=1} \left[ R_j(s^k_i, a) + \gamma V_k(s'^k_j) \right] \right|^p $
\end{itemize}
We want bound $ L_k = \Arrowvert V^* - V^{\pi_k} \Arrowvert_{p,\rho} $.

I lost my patience.

\section{Approximate Modified Policy Iteration}%
\begin{enumerate}
    \item Modified policy ieration:$ \pi_{k+1} = \arg\max_{\pi} T^{\pi} v_k, v_{k+1} = {(T^{\pi_{k+1}})}^{m} v_k $.
    \item $ c_q(m) = \max_{\pi_1, \ldots, \pi_m} \Arrowvert \frac{d(\rho P^{\pi_1} P^{\pi_2} \cdots P^{\pi_m})}{d \mu}  \Arrowvert_{q, \mu} $
\end{enumerate}
\subsection{Approximate MPI Algorithms}%
\label{sub:approximate_mpi_algorithms}

\begin{enumerate}
    \item {AMPI-V}: 
        \begin{itemize}
            \item $ \pi_{k+1}(s) \in \arg\max_{a \in A} \frac{1}{M} \sum^{M}_{j=1} (r^{(j)}(s,a) + \gamma v_k(s^{(j)}_a)) $;
            \item $ \hat v_{k+1}(s^{(i)}) = \sum^{m-1}_{t=0} \gamma^t r^{(i)}_t + \gamma^m v_k(s^{(i)}_m), i = 1, 2, \ldots, N $;
            \item Empirical error: $ \hat L^{\mathcal{F}}_k(\hat \mu; v) = \frac{1}{N} \sum^{N}_{i=1} {(\hat v_{k+1}(s^{(i)}) - v_{k+1}(s^{(i)}))}^2 $, which is used to get $ v_{k+1} $ with any regression algorithm;
            \item True error: $ L^{\mathcal{F}}_k(\mu;v) = {\Arrowvert T_{\pi_{k+1}}^{m}v_k - v \Arrowvert}_{2,\mu}^2 = \int {\left( T_{\pi_{k+1}}^{m}v_k(s) - v(s) \right)}^2 \mu(ds)$
        \end{itemize} 
    \item {AMPI-Q}:
        \begin{itemize}
            \item $ \pi_{k+1}(s) \in \arg\max_{a \in A} Q_{k}(s,a) $;
            \item $ \hat Q_{k+1}(s^{(i)}, a^{(i)}) = \sum^{m-1}_{t=0} \gamma^t r^{(i)}_t + \gamma^{m} Q_k(s^{(i)}_m, a^{(i)}_m)$;
            \item Empirical error: $ \hat L^{\mathcal{F}}_{k}(\hat \mu; Q) = \frac{1}{N} \sum^{N}_{i=1} {\left( \hat Q_{k+1}(s^{(i), a^{(i)}} - Q(s^{(i)}, a^{(i)})) \right)}^{2} $ (regression).
            \item True error: $ L^{\mathcal{F}}_{k}(\mu; Q)= \Arrowvert T^m_{\pi_{k+1}}Q_k - Q \Arrowvert^2_{2,\mu} = \int {\left( T^{m}_{\pi_{k+1}}Q_k (s,a) - Q(s,a) \right)}^2 \mu(dsda). $
        \end{itemize}
    \item {Classification-Based MPI}:
        \begin{itemize}
            \item Rewrite $ v_k = T^m_{\pi_k} v_{k-1}, \pi_{k+1} = \arg\max_{\pi} T^{\pi}(T^{m}_{\pi_k} v_{k-1}) $;
            \item $ \hat v_k(s^{(i)}) = \sum^{m-1}_{t=0} \gamma^t r^{(i)}_t + \gamma^m v_{k-1} (s^{(i)}_m) $;
            \item $ \hat L^{\mathcal{F}}_{k}(\hat \mu; v) = \frac{1}{N} \sum^{N}_{i=1} {\left( \hat v_k(s^{(i)}) - v(s^{(i)}) \right)}^2 $; (regression)
            \item $ L^{\mathcal{F}}_{k}(\mu; v) = \Arrowvert T^m_{\pi_k} v_{k-1} - v \Arrowvert^2_{2,\mu} = \int {\left( T^m_{\pi_k}v_{k-1}(s) - v(s) \right)}^2 \mu(ds) $;
            \item $ \hat Q_k(s^{(i)}, a) = \frac{1}{M} \sum^{M}_{j=1} R^{j}_{k}(s^{(i)}, a), R^j_k(s^{(i)},a) = \sum^{m}_{t=0} \gamma^t r^{(i,j)}_t + \gamma^{m+1}v_{k-1}(s^{(i,j)}_{m+1}) $;
            \item $ \hat L^{\Pi}_k(\hat \mu; \pi) = \frac{1}{N'} \sum^{N'}_{i=1} \left[ \max_{a \in A} \hat Q_k(s^{(i)}, a) - \hat Q_k(s^{(i)}, \pi(s^{(i)})) \right] $ (classification)
        \end{itemize}
\end{enumerate}

\subsection{Error Propagation}%
General error:
\begin{itemize}
    \item Greedy step error: $ \pi_k = \hat G_{\epsilon'_k} v_{k-1} \Rightarrow \forall \pi', T_{\pi'} v_{k-1} \preceq T_{\pi_k} v_{k-1} + \epsilon'_k $;
    \item Evaluation step error: $ v_k = T^m_{\pi_k} v_{k-1} + \epsilon_k $
\end{itemize}

Errors parameters:
\begin{itemize}
    \item $ d_k = V^* - T^m_{\pi_k} V_{k-1} = V^* - (V_k - \epsilon_k) $;
    \item $ s_k = T^m_{\pi_k}V_{k-1} - V^{\pi_k} = (V_k - \epsilon_k) - V^{\pi_k} $;
    \item $ b_k = V_k - T_{\pi_{k+1}}V_k $;
    \item $ l_k = V^* - V^{\pi_k} = d_k + s_k $. (We want bound this.)
\end{itemize}

\begin{enumerate}
    \item Bounding $ b_k $:
        \begin{align*}
            b_k =& V_k - \epsilon_k - T_{\pi_k}(v_k - \epsilon_k) + \epsilon_k - \gamma P_{\pi_k} \epsilon_k + T_{\pi_k} V_k - T_{\pi_{k+1}} V_k\\
            \preceq& T^{m}_{\pi_k} V_{k-1} - T_{\pi_k}T^{m}_{\pi_k} V_{k-1} + (I - \gamma P_{\pi_k}) \epsilon_k + \epsilon'_{k+1}\\
            =& {(\gamma P_{\pi_k})}^{m} (V_{k-1} - T_{\pi_k} V_{k-1})+ (I - \gamma P_{\pi_k}) \epsilon_k + \epsilon'_{k+1}\\
            =& {(\gamma P_{\pi_k})}^{m} b_{k-1} + ((I - \gamma P_{\pi_k}) \epsilon_k + \epsilon'_{k+1})\\
            =& {(\gamma P_{\pi_k})}^{m} b_{k-1} + x_k
        \end{align*}
    \item Bounding $ d_k $:
        \begin{align*}
            d_{k+1} =& V^* - T^m_{\pi_{k+1}} V_k\\
            =& T_{\pi^*} V^{*} - T_{\pi^*} V_k + T_{\pi^*} V_k - T_{\pi_{k+1}} V_k + \sum^{m-1}_{j=1} \left[ T^j_{\pi_{k+1}}V_k - T^{j+1}_{\pi_{k+1}} V_k \right]\\
            \preceq& \gamma P_{\pi^*} (V^* - V_k) + \epsilon'_{k+1} + \sum^{m-1}_{j=1} {(\gamma P_{\pi_{k+1}})}^{j} b_k\\
            =& \gamma P_{\pi^*} (V^* - T^m_{\pi_{k}}V_{k-1} - \epsilon_k) + \epsilon'_{k+1} + \sum^{m-1}_{j=1} {(\gamma P_{\pi_{k+1}})}^{j} b_k\\
            =& \gamma P_{\pi^*} d_k +(- \gamma P_{\pi^*} \epsilon_k + \epsilon'_{k+1}) + \sum^{m-1}_{j=1} {(\gamma P_{\pi_{k+1}})}^{j} b_k\\
            =& \gamma P_{\pi^*} d_k + y_k + \sum^{m-1}_{j=1} {(\gamma P_{\pi_{k+1}})}^{j} b_k\\
        \end{align*}
    \item Bounding $ s_k $:
        \begin{align*}
            s_k =& T^m_{\pi_k} V_{k-1} - V_{\pi_k} = T^m_{\pi_k} V_{k-1} - T^{\infty}_{\pi_k} V_{{k-1}} 
            = {(\gamma P_{\pi_k})}^{m} \left( V_{k-1} - T^{\infty}_{\pi_k} V_{k-1} \right) \\
            =& {(\gamma P_{\pi_k})}^{m} \sum^{\infty}_{j=0} \left[ T^j_{\pi_k} V_{k-1} - T^{j+1}_{\pi_k} V_{k-1} \right]
            = {(\gamma P_{\pi_k})}^{m} \sum^{\infty}_{j=0} {(\gamma P_{\pi_k})}^{j} (V_{k-1} - T_{\pi_k} V_{k-1})\\
            =& {(\gamma P_{\pi_k})}^{m} {(I - \gamma P_{\pi_k})}^{-1} b_{k-1}
        \end{align*}
\end{enumerate}

\begin{definition}
    We define $ \mathbb{P}_n $ as the smallest set of discounted transition kernels that are defined as follows:
    \begin{enumerate}
        \item $ \forall \left\{ \pi_1, \ldots, \pi_n \right\}, (\gamma P_{\pi_1})(\gamma P_{\pi_2})\ldots (\gamma P_{\pi_n}) \in \mathbb{P}_n $;
        \item $ \forall \alpha \in [0,1] $ and $ P_1, P_2 \in \mathbb{P}_n $, we have $ \alpha P_1 + (1 - \alpha) P_2 \in \mathbb{P}_n $.
    \end{enumerate}
\end{definition}

And we denote any element of $ \mathbb{P}_n $, $ \Gamma^n $.
\begin{enumerate}
    \item $ b_k \le \sum^{k}_{i=1} \Gamma^{m(k-i)} x_i + \Gamma^{mk}b_0 $;
    \item $ d_k \le \sum^{k-1}_{i=0} \Gamma^{k-1-i} \left( y_i + \sum^{m-1}_{l=1} \Gamma^{l} b_i\right) + \Gamma^{k}d_0 $;
        \begin{align*}
            d_k \le \sum^{k}_{i=1}  \Gamma^{i-1} y_{k-i} 
            + \sum^{k-1}_{i=1} \sum^{mi-1}_{j=i} \Gamma^j x_{k-i}
            + \sum^{mk-1}_{i=k} \Gamma^{i} b_0 + \Gamma^k d_0.
        \end{align*}
    \item $ s_k = \Gamma^m \sum^{\infty}_{i=0} \Gamma^i b_{k-1} = \sum^{\infty}_{i=0} \Gamma^{m+i}b_{k-1} = \sum^{k-1}_{i=1} \sum^{\infty}_{j=mi} \Gamma^{j} x_{k-i} + \sum^{\infty}_{j = mk} \Gamma^j b_0 $.
        \item $ l_k \le \sum^{k}_{i=1} \Gamma^{i-1} y_{k-i} + \sum^{k-1}_{i=1} \sum^{\infty}_{j=i} \Gamma^{j} x_{k-i} + \sum^{\infty}_{j=k} \Gamma^j b_0 + \Gamma^k d_0 $.
\end{enumerate}
\begin{lemma}
    \begin{enumerate}
        \item After k iterations, the losses of AMPI-V and AMPI-Q satisfy
            \[
                l_k \le 2 \sum^{k-1}_{i=1} \sum^{\infty}_{j=i} \Gamma^{j} \left| \epsilon_{k-i} \right|
                + \sum^{k-1}_{i=0} \sum^{\infty}_{j=i} \Gamma^j \left| \epsilon'_{k-i} \right| + h(k);
            \]
        \item The loss of CBMPI satisfies:
            \[
                l_k \le 2 \sum^{k-2}_{i=1} \sum^{\infty}_{j=i+m} \Gamma^{j} \left| \epsilon_{k-i-1} \right|
                + \sum^{k-1}_{i=0} \sum^{\infty}_{j=i} \Gamma^j \left| \epsilon'_{k-i} \right| + h(k);
            \]
        \item $ h(k) = 2 \sum^{\infty}_{j=k} \Gamma^j \left| d_0 \right| $ or $ h(h) = 2 \sum^{\infty}_{j=k} \Gamma^j \left| b_0 \right| $.
    \end{enumerate}
\end{lemma}

It's easy to obtain $ \limsup_{k \rightarrow \infty} {\Arrowvert l_k \Arrowvert}_\infty \le \frac{2\gamma \epsilon + \epsilon'}{{(1 - \gamma)}^{2}}  $


\end{document}
